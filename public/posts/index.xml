<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Yuan Meng</title>
    <link>http://localhost:1313/posts/</link>
    <description>Recent content in Posts on Yuan Meng</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <managingEditor>mycaptainmy@gmail.com (Yuan Meng)</managingEditor>
    <webMaster>mycaptainmy@gmail.com (Yuan Meng)</webMaster>
    <copyright>Yuan Meng</copyright>
    <lastBuildDate>Mon, 01 Jan 0001 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Down the Rabbit Hole: Sequential User Modeling</title>
      <link>http://localhost:1313/posts/seq_user_modeling/</link>
      <pubDate>Sun, 10 Nov 2024 00:00:00 +0000</pubDate><author>mycaptainmy@gmail.com (Yuan Meng)</author>
      <guid>http://localhost:1313/posts/seq_user_modeling/</guid>
      <description>&lt;figure&#xA;  role=&#34;note&#34;&#xA;  id=&#34;admonition-00&#34;&#xA;  aria-labelledby=&#34;admonition-caption-00&#34;&#xA;  class=&#34;admonition note  not-prose&#34;&#xA;&gt;&#xA;  &lt;div class=&#34;flex items-center space-x-2 pb-2 font-semibold&#34;&gt;&#xA;      &lt;svg&#xA;  xmlns=&#34;http://www.w3.org/2000/svg&#34;&#xA;  width=&#34;24&#34;&#xA;  height=&#34;24&#34;&#xA;  fill=&#34;none&#34;&#xA;  stroke=&#34;currentColor&#34;&#xA;  stroke-linecap=&#34;round&#34;&#xA;  stroke-linejoin=&#34;round&#34;&#xA;  stroke-width=&#34;2&#34;&#xA;  class=&#34;lucide lucide-info block&#34;&#xA;&gt;&#xA;  &lt;circle cx=&#34;12&#34; cy=&#34;12&#34; r=&#34;10&#34; /&gt;&#xA;  &lt;path d=&#34;M12 16v-4M12 8h.01&#34; /&gt;&#xA;&lt;/svg&gt;&#xA;&#xA;    &lt;figcaption id=&#34;admonition-caption-00&#34;&gt;&#xA;        Note&#xA;    &lt;/figcaption&gt;&#xA;  &lt;/div&gt;&#xA;&#xA;  &lt;div class=&#34;prose pl-8 text-inherit marker:text-inherit&#34;&gt;&#xA;    Coming soon&amp;hellip;.&#xA;  &lt;/div&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;h2 id=&#34;references&#34; class=&#34;scroll-mt-8 group&#34;&gt;&#xA;  References&#xA;  &#xA;    &lt;a href=&#34;#references&#34;&#xA;        class=&#34;no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block&#34;&#xA;        aria-hidden=&#34;true&#34; title=&#34;Link to this heading&#34; tabindex=&#34;-1&#34;&gt;&#xA;        &lt;svg&#xA;  xmlns=&#34;http://www.w3.org/2000/svg&#34;&#xA;  width=&#34;16&#34;&#xA;  height=&#34;16&#34;&#xA;  fill=&#34;none&#34;&#xA;  stroke=&#34;currentColor&#34;&#xA;  stroke-linecap=&#34;round&#34;&#xA;  stroke-linejoin=&#34;round&#34;&#xA;  stroke-width=&#34;2&#34;&#xA;  class=&#34;lucide lucide-link w-4 h-4 block&#34;&#xA;  viewBox=&#34;0 0 24 24&#34;&#xA;&gt;&#xA;  &lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; /&gt;&#xA;  &lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; /&gt;&#xA;&lt;/svg&gt;&#xA;&#xA;    &lt;/a&gt;&#xA;  &#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;papers&#34; class=&#34;scroll-mt-8 group&#34;&gt;&#xA;  Papers&#xA;  &#xA;    &lt;a href=&#34;#papers&#34;&#xA;        class=&#34;no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block&#34;&#xA;        aria-hidden=&#34;true&#34; title=&#34;Link to this heading&#34; tabindex=&#34;-1&#34;&gt;&#xA;        &lt;svg&#xA;  xmlns=&#34;http://www.w3.org/2000/svg&#34;&#xA;  width=&#34;16&#34;&#xA;  height=&#34;16&#34;&#xA;  fill=&#34;none&#34;&#xA;  stroke=&#34;currentColor&#34;&#xA;  stroke-linecap=&#34;round&#34;&#xA;  stroke-linejoin=&#34;round&#34;&#xA;  stroke-width=&#34;2&#34;&#xA;  class=&#34;lucide lucide-link w-4 h-4 block&#34;&#xA;  viewBox=&#34;0 0 24 24&#34;&#xA;&gt;&#xA;  &lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; /&gt;&#xA;  &lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; /&gt;&#xA;&lt;/svg&gt;&#xA;&#xA;    &lt;/a&gt;&#xA;  &#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://openreview.net/forum?id=Gny0PVtKz2&#34;&gt;&lt;em&gt;ConvFormer: Revisiting Token-mixers for Sequential User Modeling&lt;/em&gt;&lt;/a&gt; (2024) by Wang et al., &lt;em&gt;ICLR&lt;/em&gt;.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2205.04507&#34;&gt;&lt;em&gt;PinnerFormer: Sequence Modeling for User Representation at Pinterest&lt;/em&gt;&lt;/a&gt; (2022) by Pancha et al., &lt;em&gt;KDD&lt;/em&gt;.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2306.00248&#34;&gt;&lt;em&gt;TransAct: Transformer-based Realtime User Action Model for Recommendation at Pinterest&lt;/em&gt;&lt;/a&gt; (2024) by Xia et al., &lt;em&gt;KDD&lt;/em&gt;.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;blogposts&#34; class=&#34;scroll-mt-8 group&#34;&gt;&#xA;  Blogposts&#xA;  &#xA;    &lt;a href=&#34;#blogposts&#34;&#xA;        class=&#34;no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block&#34;&#xA;        aria-hidden=&#34;true&#34; title=&#34;Link to this heading&#34; tabindex=&#34;-1&#34;&gt;&#xA;        &lt;svg&#xA;  xmlns=&#34;http://www.w3.org/2000/svg&#34;&#xA;  width=&#34;16&#34;&#xA;  height=&#34;16&#34;&#xA;  fill=&#34;none&#34;&#xA;  stroke=&#34;currentColor&#34;&#xA;  stroke-linecap=&#34;round&#34;&#xA;  stroke-linejoin=&#34;round&#34;&#xA;  stroke-width=&#34;2&#34;&#xA;  class=&#34;lucide lucide-link w-4 h-4 block&#34;&#xA;  viewBox=&#34;0 0 24 24&#34;&#xA;&gt;&#xA;  &lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; /&gt;&#xA;  &lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; /&gt;&#xA;&lt;/svg&gt;&#xA;&#xA;    &lt;/a&gt;&#xA;  &#xA;&lt;/h3&gt;&#xA;&lt;ol start=&#34;4&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://research.google/blog/transformers-in-music-recommendation/&#34;&gt;&lt;em&gt;Transformers in Music Recommendation&lt;/em&gt;&lt;/a&gt; by Google Research.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.com/pinterest-engineering/large-scale-user-sequences-at-pinterest-78a5075a3fe9&#34;&gt;&lt;em&gt;Large-scale User Sequences at Pinterest&lt;/em&gt;&lt;/a&gt; by Pinterest Engineering.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.com/pinterest-engineering/user-action-sequence-modeling-for-pinterest-ads-engagement-modeling-21139cab8f4e&#34;&gt;&lt;em&gt;User Action Sequence Modeling for Pinterest Ads Engagement Modeling&lt;/em&gt;&lt;/a&gt; by Pinterest Engineering.&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>(Opinionated) Guide to ML Engineer Job Hunting</title>
      <link>http://localhost:1313/posts/mle_interviews/</link>
      <pubDate>Tue, 15 Oct 2024 00:00:00 +0000</pubDate><author>mycaptainmy@gmail.com (Yuan Meng)</author>
      <guid>http://localhost:1313/posts/mle_interviews/</guid>
      <description>&lt;h2 id=&#34;the-marriage-analogy&#34; class=&#34;scroll-mt-8 group&#34;&gt;&#xA;  The Marriage Analogy&#xA;  &#xA;    &lt;a href=&#34;#the-marriage-analogy&#34;&#xA;        class=&#34;no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block&#34;&#xA;        aria-hidden=&#34;true&#34; title=&#34;Link to this heading&#34; tabindex=&#34;-1&#34;&gt;&#xA;        &lt;svg&#xA;  xmlns=&#34;http://www.w3.org/2000/svg&#34;&#xA;  width=&#34;16&#34;&#xA;  height=&#34;16&#34;&#xA;  fill=&#34;none&#34;&#xA;  stroke=&#34;currentColor&#34;&#xA;  stroke-linecap=&#34;round&#34;&#xA;  stroke-linejoin=&#34;round&#34;&#xA;  stroke-width=&#34;2&#34;&#xA;  class=&#34;lucide lucide-link w-4 h-4 block&#34;&#xA;  viewBox=&#34;0 0 24 24&#34;&#xA;&gt;&#xA;  &lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; /&gt;&#xA;  &lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; /&gt;&#xA;&lt;/svg&gt;&#xA;&#xA;    &lt;/a&gt;&#xA;  &#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Over 2 years ago, I wrote a &lt;a href=&#34;https://www.yuan-meng.com/posts/newgrads/&#34;&gt;blog post&lt;/a&gt; on how to find jobs as a new grad data scientist (as a twist of fate, I never worked as a product data scientist but instead became an ML engineer at DoorDash). Back in 2021, I cared a ton about interview skills, answer &amp;ldquo;frameworks&amp;rdquo;, and whatnot, which may still come handy at New Grad or Early Career levels. For experienced hires, however, I think of interviews as some sort of marriage proposal &amp;mdash; &lt;em&gt;it&amp;rsquo;s something you can rehearse but can never force&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Is Human Vision More like CNN or Vision Transformer?</title>
      <link>http://localhost:1313/posts/human_vision/</link>
      <pubDate>Sun, 13 Oct 2024 00:00:00 +0000</pubDate><author>mycaptainmy@gmail.com (Yuan Meng)</author>
      <guid>http://localhost:1313/posts/human_vision/</guid>
      <description>&lt;h2 id=&#34;engineer-the-mind&#34; class=&#34;scroll-mt-8 group&#34;&gt;&#xA;  Engineer the Mind&#xA;  &#xA;    &lt;a href=&#34;#engineer-the-mind&#34;&#xA;        class=&#34;no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block&#34;&#xA;        aria-hidden=&#34;true&#34; title=&#34;Link to this heading&#34; tabindex=&#34;-1&#34;&gt;&#xA;        &lt;svg&#xA;  xmlns=&#34;http://www.w3.org/2000/svg&#34;&#xA;  width=&#34;16&#34;&#xA;  height=&#34;16&#34;&#xA;  fill=&#34;none&#34;&#xA;  stroke=&#34;currentColor&#34;&#xA;  stroke-linecap=&#34;round&#34;&#xA;  stroke-linejoin=&#34;round&#34;&#xA;  stroke-width=&#34;2&#34;&#xA;  class=&#34;lucide lucide-link w-4 h-4 block&#34;&#xA;  viewBox=&#34;0 0 24 24&#34;&#xA;&gt;&#xA;  &lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; /&gt;&#xA;  &lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; /&gt;&#xA;&lt;/svg&gt;&#xA;&#xA;    &lt;/a&gt;&#xA;  &#xA;&lt;/h2&gt;&#xA;&lt;p&gt;In Winter 2015, after coming back from grad school interviews in the States, I told my dad over hotpot that I was going to study &lt;a href=&#34;https://en.wikipedia.org/wiki/Cognitive_science&#34;&gt;cognitive science&lt;/a&gt; at Berkeley.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Negative Sampling for Learning Two-Tower Networks</title>
      <link>http://localhost:1313/posts/negative_sampling/</link>
      <pubDate>Mon, 02 Sep 2024 00:00:00 +0000</pubDate><author>mycaptainmy@gmail.com (Yuan Meng)</author>
      <guid>http://localhost:1313/posts/negative_sampling/</guid>
      <description>&lt;h2 id=&#34;web-scale-recommender-systems&#34; class=&#34;scroll-mt-8 group&#34;&gt;&#xA;  Web-Scale Recommender Systems&#xA;  &#xA;    &lt;a href=&#34;#web-scale-recommender-systems&#34;&#xA;        class=&#34;no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block&#34;&#xA;        aria-hidden=&#34;true&#34; title=&#34;Link to this heading&#34; tabindex=&#34;-1&#34;&gt;&#xA;        &lt;svg&#xA;  xmlns=&#34;http://www.w3.org/2000/svg&#34;&#xA;  width=&#34;16&#34;&#xA;  height=&#34;16&#34;&#xA;  fill=&#34;none&#34;&#xA;  stroke=&#34;currentColor&#34;&#xA;  stroke-linecap=&#34;round&#34;&#xA;  stroke-linejoin=&#34;round&#34;&#xA;  stroke-width=&#34;2&#34;&#xA;  class=&#34;lucide lucide-link w-4 h-4 block&#34;&#xA;  viewBox=&#34;0 0 24 24&#34;&#xA;&gt;&#xA;  &lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; /&gt;&#xA;  &lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; /&gt;&#xA;&lt;/svg&gt;&#xA;&#xA;    &lt;/a&gt;&#xA;  &#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;two-stage-architecture&#34; class=&#34;scroll-mt-8 group&#34;&gt;&#xA;  Two-Stage Architecture&#xA;  &#xA;    &lt;a href=&#34;#two-stage-architecture&#34;&#xA;        class=&#34;no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block&#34;&#xA;        aria-hidden=&#34;true&#34; title=&#34;Link to this heading&#34; tabindex=&#34;-1&#34;&gt;&#xA;        &lt;svg&#xA;  xmlns=&#34;http://www.w3.org/2000/svg&#34;&#xA;  width=&#34;16&#34;&#xA;  height=&#34;16&#34;&#xA;  fill=&#34;none&#34;&#xA;  stroke=&#34;currentColor&#34;&#xA;  stroke-linecap=&#34;round&#34;&#xA;  stroke-linejoin=&#34;round&#34;&#xA;  stroke-width=&#34;2&#34;&#xA;  class=&#34;lucide lucide-link w-4 h-4 block&#34;&#xA;  viewBox=&#34;0 0 24 24&#34;&#xA;&gt;&#xA;  &lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; /&gt;&#xA;  &lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; /&gt;&#xA;&lt;/svg&gt;&#xA;&#xA;    &lt;/a&gt;&#xA;  &#xA;&lt;/h3&gt;&#xA;&lt;p&gt;The iconic YouTube paper (&lt;a href=&#34;https://research.google/pubs/deep-neural-networks-for-youtube-recommendations/&#34;&gt;Covington et al., 2016&lt;/a&gt;) introduced a two-stage architecture that since became the industry standard for large-scale recommender systems:&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Annotated Multi-Task Ranker: An MMoE Code Example</title>
      <link>http://localhost:1313/posts/mtml/</link>
      <pubDate>Fri, 05 Jul 2024 00:00:00 +0000</pubDate><author>mycaptainmy@gmail.com (Yuan Meng)</author>
      <guid>http://localhost:1313/posts/mtml/</guid>
      <description>&lt;p&gt;Natural Language Processing (NLP) has an abundance of intuitively explained tutorials with code, such as Andrej Kaparthy&amp;rsquo;s &lt;a href=&#34;https://karpathy.ai/zero-to-hero.html&#34;&gt;Neural Networks: Zero to Hero&lt;/a&gt;, the viral &lt;a href=&#34;https://jalammar.github.io/illustrated-transformer/&#34;&gt;The Illustrated Transformer&lt;/a&gt; and its successor &lt;a href=&#34;https://nlp.seas.harvard.edu/annotated-transformer/&#34;&gt;The Annotated Transformer&lt;/a&gt;, Umar Jamil&amp;rsquo;s YouTube &lt;a href=&#34;https://www.youtube.com/@umarjamilai&#34;&gt;series&lt;/a&gt; dissecting SOTA models and the companion &lt;a href=&#34;https://github.com/hkproj&#34;&gt;repo&lt;/a&gt;, among others.&lt;/p&gt;&#xA;&lt;p&gt;When it comes to Search/Ads/Recommendations (&amp;ldquo;ÊêúÂπøÊé®&amp;rdquo;), however, intuitive explanations accompanied by code are rare. Company engineering blogs tend to focus on high-level system designs, and many top conference (e.g., KDD/RecSys/SIGIR) papers don&amp;rsquo;t share code. In this post, I explain the iconic Multi-gate Mixture-of-Experts (MMoE) paper (&lt;a href=&#34;https://dl.acm.org/doi/pdf/10.1145/3219819.3220007&#34;&gt;Ma et al., 2018&lt;/a&gt;) using implementation in the popular &lt;a href=&#34;https://github.com/shenweichen/DeepCTR-Torch&#34;&gt;DeepCTR-Torch&lt;/a&gt; repo, to teach myself and readers how the authors&amp;rsquo; blueprint translates into code.&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Introduction to Embedding-Based Retrieval</title>
      <link>http://localhost:1313/posts/ebr/</link>
      <pubDate>Sat, 22 Jun 2024 00:00:00 +0000</pubDate><author>mycaptainmy@gmail.com (Yuan Meng)</author>
      <guid>http://localhost:1313/posts/ebr/</guid>
      <description>&lt;h2 id=&#34;so-what-is-an-embedding&#34; class=&#34;scroll-mt-8 group&#34;&gt;&#xA;  So, What is an Embedding?&#xA;  &#xA;    &lt;a href=&#34;#so-what-is-an-embedding&#34;&#xA;        class=&#34;no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block&#34;&#xA;        aria-hidden=&#34;true&#34; title=&#34;Link to this heading&#34; tabindex=&#34;-1&#34;&gt;&#xA;        &lt;svg&#xA;  xmlns=&#34;http://www.w3.org/2000/svg&#34;&#xA;  width=&#34;16&#34;&#xA;  height=&#34;16&#34;&#xA;  fill=&#34;none&#34;&#xA;  stroke=&#34;currentColor&#34;&#xA;  stroke-linecap=&#34;round&#34;&#xA;  stroke-linejoin=&#34;round&#34;&#xA;  stroke-width=&#34;2&#34;&#xA;  class=&#34;lucide lucide-link w-4 h-4 block&#34;&#xA;  viewBox=&#34;0 0 24 24&#34;&#xA;&gt;&#xA;  &lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; /&gt;&#xA;  &lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; /&gt;&#xA;&lt;/svg&gt;&#xA;&#xA;    &lt;/a&gt;&#xA;  &#xA;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Embedding&#34;&gt;Embedding&lt;/a&gt; is a classic idea in mathematical topology and machine learning (click ‚ñ∂ for definitions). You can think of embeddings as a special type of vectors.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Attention as Soft Dictionary Lookup</title>
      <link>http://localhost:1313/posts/attention_as_dict/</link>
      <pubDate>Sat, 09 Mar 2024 00:00:00 +0000</pubDate><author>mycaptainmy@gmail.com (Yuan Meng)</author>
      <guid>http://localhost:1313/posts/attention_as_dict/</guid>
      <description>&lt;h2 id=&#34;the-dictionary-metaphor-&#34; class=&#34;scroll-mt-8 group&#34;&gt;&#xA;  The Dictionary Metaphor üîëüìö&#xA;  &#xA;    &lt;a href=&#34;#the-dictionary-metaphor-&#34;&#xA;        class=&#34;no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block&#34;&#xA;        aria-hidden=&#34;true&#34; title=&#34;Link to this heading&#34; tabindex=&#34;-1&#34;&gt;&#xA;        &lt;svg&#xA;  xmlns=&#34;http://www.w3.org/2000/svg&#34;&#xA;  width=&#34;16&#34;&#xA;  height=&#34;16&#34;&#xA;  fill=&#34;none&#34;&#xA;  stroke=&#34;currentColor&#34;&#xA;  stroke-linecap=&#34;round&#34;&#xA;  stroke-linejoin=&#34;round&#34;&#xA;  stroke-width=&#34;2&#34;&#xA;  class=&#34;lucide lucide-link w-4 h-4 block&#34;&#xA;  viewBox=&#34;0 0 24 24&#34;&#xA;&gt;&#xA;  &lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; /&gt;&#xA;  &lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; /&gt;&#xA;&lt;/svg&gt;&#xA;&#xA;    &lt;/a&gt;&#xA;  &#xA;&lt;/h2&gt;&#xA;&lt;p&gt;By now, the scaled-dot product attention formula might have burned into our brains üß†, $\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$, yet still this brilliant metaphor from Kevin Murphy&amp;rsquo;s PML book gives it a refreshed interpretation &amp;mdash;&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Evolution of Learning to Rank</title>
      <link>http://localhost:1313/posts/ltr/</link>
      <pubDate>Sat, 17 Feb 2024 00:00:00 +0000</pubDate><author>mycaptainmy@gmail.com (Yuan Meng)</author>
      <guid>http://localhost:1313/posts/ltr/</guid>
      <description>&lt;h2 id=&#34;first-thing-first&#34; class=&#34;scroll-mt-8 group&#34;&gt;&#xA;  First Thing First&#xA;  &#xA;    &lt;a href=&#34;#first-thing-first&#34;&#xA;        class=&#34;no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block&#34;&#xA;        aria-hidden=&#34;true&#34; title=&#34;Link to this heading&#34; tabindex=&#34;-1&#34;&gt;&#xA;        &lt;svg&#xA;  xmlns=&#34;http://www.w3.org/2000/svg&#34;&#xA;  width=&#34;16&#34;&#xA;  height=&#34;16&#34;&#xA;  fill=&#34;none&#34;&#xA;  stroke=&#34;currentColor&#34;&#xA;  stroke-linecap=&#34;round&#34;&#xA;  stroke-linejoin=&#34;round&#34;&#xA;  stroke-width=&#34;2&#34;&#xA;  class=&#34;lucide lucide-link w-4 h-4 block&#34;&#xA;  viewBox=&#34;0 0 24 24&#34;&#xA;&gt;&#xA;  &lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; /&gt;&#xA;  &lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; /&gt;&#xA;&lt;/svg&gt;&#xA;&#xA;    &lt;/a&gt;&#xA;  &#xA;&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Enigmas of the universe &lt;br/&gt; Cannot be known without a search &lt;br/&gt; &amp;mdash; Epica, &lt;a href=&#34;https://open.spotify.com/track/34Oz0bzAq7E1aUnKksPfJJ?si=9eabd1446a6a4ccc&#34;&gt;&lt;em&gt;Omega&lt;/em&gt;&lt;/a&gt; (2021)&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;In &lt;em&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/The_Rainmaker_(1997_film)&#34;&gt;The Rainmaker (1997)&lt;/a&gt;&lt;/em&gt;,  the freshly graduated lawyer Rudy Baylor faced off against a giant insurance firm in his debut case, almost getting buried by mountains of case files that the corporate lawyers never expected him to sift through. If only Rudy had a search engine that &lt;em&gt;retrieves&lt;/em&gt; all files mentioning suspicious denials and &lt;em&gt;ranks&lt;/em&gt; them from most to least relevant, the case prep would&amp;rsquo;ve been a breeze.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Autocompletion for Search Enginees</title>
      <link>http://localhost:1313/posts/autocomplete/</link>
      <pubDate>Sat, 06 Jan 2024 00:00:00 +0000</pubDate><author>mycaptainmy@gmail.com (Yuan Meng)</author>
      <guid>http://localhost:1313/posts/autocomplete/</guid>
      <description>&lt;p&gt;Autocompletion dates back half a century ago (&lt;a href=&#34;https://www.doc.ic.ac.uk/~shm/MI/mi3.html&#34;&gt;Longuet-Higgins &amp;amp; Ortony, 1968&lt;/a&gt;), initially designed to save keystrokes as people type and help those with physical disabilities type faster. The incomplete user input is the &lt;strong&gt;&amp;ldquo;query prefix&amp;rdquo;&lt;/strong&gt; and suggested ways of extending the prefix into a full query are &lt;strong&gt;&amp;ldquo;query completions&amp;rdquo;&lt;/strong&gt;. This feature is essential to modern text editors and search engines.&lt;/p&gt;&#xA;&lt;figure&gt;&lt;img src=&#34;https://www.dropbox.com/scl/fi/a112bhnp4bctso6fwn72x/Screenshot-2024-01-06-at-4.27.56-PM.png?rlkey=bphpjszgirskda9i142icb5os&amp;amp;raw=1&#34; width=&#34;450&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;This blog post summarizes key ideas from the survey paper &lt;a href=&#34;https://www.nowpublishers.com/article/Details/INR-055&#34;&gt;&lt;em&gt;A Survey of Query Auto Completion in Information Retrieval&lt;/em&gt;&lt;/a&gt;, recommended by my Search teammate at DoorDash.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Teaching A Peceptron to See</title>
      <link>http://localhost:1313/posts/perceptron/</link>
      <pubDate>Sun, 02 Jul 2023 00:00:00 +0000</pubDate><author>mycaptainmy@gmail.com (Yuan Meng)</author>
      <guid>http://localhost:1313/posts/perceptron/</guid>
      <description>&lt;p&gt;Ten years after the ImageNet Challenge thawed the last AI winter, ChaptGPT and generative AI have become part of our everyday life and colloquial language, like (almost) no one has imagined just 2 years back. As increasingly more folks aspire to foray into the field of ML/AI, I can&amp;rsquo;t help but think about a lesson from my guitar teacher:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Everyone wants to start playing the songs they love right off the bat, but without nailing seemingly &amp;ldquo;boring&amp;rdquo; building blocks such as scales, harmonies, and rhythms, the songs you love will sound like a nightmare&amp;hellip;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Code ML Algorithms From Scratch</title>
      <link>http://localhost:1313/posts/md_coding/</link>
      <pubDate>Wed, 22 Jun 2022 00:00:00 +0000</pubDate><author>mycaptainmy@gmail.com (Yuan Meng)</author>
      <guid>http://localhost:1313/posts/md_coding/</guid>
      <description>&lt;p&gt;Coding interviews can mean different things for &amp;ldquo;traditional&amp;rdquo; software engineers (back-end, front-end, full-stack, etc.) and engineers with a machine learning focus. Apart from LeetCode-style questions, ML engineers (as well as applied scientists, research engineers, and, occasionally, machine learning data scientists) may be asked to implement a classic ML algorithm from scratch during an interview.&lt;/p&gt;&#xA;&lt;p&gt;This may sound scary if you&amp;rsquo;ve only used libraries to train models without understanding how learning algorithms work under the hood. Moreover, there are way too many algorithms to memorize. The good news is, only 4 algorithms are commonly asked in interviews: &lt;strong&gt;Linear regression&lt;/strong&gt;, &lt;strong&gt;logistic regression&lt;/strong&gt;, &lt;strong&gt;k-nearest neighbors&lt;/strong&gt; (k-NN), and &lt;strong&gt;k-means&lt;/strong&gt;. You&amp;rsquo;re probably not gonna code a transformer on the fly in 45 minutes. Let&amp;rsquo;s implement each using vanilla NumPy (and some built-in libraries).&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Quirky) Roadmap for New Grad Data Scientists</title>
      <link>http://localhost:1313/posts/newgrads/</link>
      <pubDate>Sun, 13 Mar 2022 00:00:00 +0000</pubDate><author>mycaptainmy@gmail.com (Yuan Meng)</author>
      <guid>http://localhost:1313/posts/newgrads/</guid>
      <description>&lt;h2 id=&#34;new-grad-timeline&#34; class=&#34;scroll-mt-8 group&#34;&gt;&#xA;  New Grad Timeline&#xA;  &#xA;    &lt;a href=&#34;#new-grad-timeline&#34;&#xA;        class=&#34;no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block&#34;&#xA;        aria-hidden=&#34;true&#34; title=&#34;Link to this heading&#34; tabindex=&#34;-1&#34;&gt;&#xA;        &lt;svg&#xA;  xmlns=&#34;http://www.w3.org/2000/svg&#34;&#xA;  width=&#34;16&#34;&#xA;  height=&#34;16&#34;&#xA;  fill=&#34;none&#34;&#xA;  stroke=&#34;currentColor&#34;&#xA;  stroke-linecap=&#34;round&#34;&#xA;  stroke-linejoin=&#34;round&#34;&#xA;  stroke-width=&#34;2&#34;&#xA;  class=&#34;lucide lucide-link w-4 h-4 block&#34;&#xA;  viewBox=&#34;0 0 24 24&#34;&#xA;&gt;&#xA;  &lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; /&gt;&#xA;  &lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; /&gt;&#xA;&lt;/svg&gt;&#xA;&#xA;    &lt;/a&gt;&#xA;  &#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Since last November, I regularly get questions about how to get data science jobs. I&amp;rsquo;ve hesitated to give advice because no advice applies to everyone. As more people ask, however, I want to write a post for those in my shoes:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Causal Inference in Data Science</title>
      <link>http://localhost:1313/posts/causality/causality/</link>
      <pubDate>Fri, 12 Nov 2021 00:00:00 +0000</pubDate><author>mycaptainmy@gmail.com (Yuan Meng)</author>
      <guid>http://localhost:1313/posts/causality/causality/</guid>
      <description>&lt;p&gt;What do you see? üëÄ&lt;/p&gt;&#xA;&lt;figure&gt;&lt;img src=&#34;https://www.dropbox.com/s/gfiw187r502jb1l/1t1_redgreen_2sec.gif?raw=1&#34; width=&#34;350&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;You&amp;rsquo;re probably thinking, &lt;em&gt;&amp;ldquo;The red block stopped, right after which the green block started to move coincidentally.&amp;rdquo;&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Nice try&amp;hellip; I know what you&amp;rsquo;re thinking, &lt;em&gt;&amp;ldquo;The red block &lt;u&gt;made&lt;/u&gt; the green one move&amp;rdquo;&lt;/em&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;why-ask-why&#34; class=&#34;scroll-mt-8 group&#34;&gt;&#xA;  Why Ask Why?&#xA;  &#xA;    &lt;a href=&#34;#why-ask-why&#34;&#xA;        class=&#34;no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block&#34;&#xA;        aria-hidden=&#34;true&#34; title=&#34;Link to this heading&#34; tabindex=&#34;-1&#34;&gt;&#xA;        &lt;svg&#xA;  xmlns=&#34;http://www.w3.org/2000/svg&#34;&#xA;  width=&#34;16&#34;&#xA;  height=&#34;16&#34;&#xA;  fill=&#34;none&#34;&#xA;  stroke=&#34;currentColor&#34;&#xA;  stroke-linecap=&#34;round&#34;&#xA;  stroke-linejoin=&#34;round&#34;&#xA;  stroke-width=&#34;2&#34;&#xA;  class=&#34;lucide lucide-link w-4 h-4 block&#34;&#xA;  viewBox=&#34;0 0 24 24&#34;&#xA;&gt;&#xA;  &lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; /&gt;&#xA;  &lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; /&gt;&#xA;&lt;/svg&gt;&#xA;&#xA;    &lt;/a&gt;&#xA;  &#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;we-cant-help-but-think-about-causation&#34; class=&#34;scroll-mt-8 group&#34;&gt;&#xA;  We can&amp;rsquo;t help but think about causation&#xA;  &#xA;    &lt;a href=&#34;#we-cant-help-but-think-about-causation&#34;&#xA;        class=&#34;no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block&#34;&#xA;        aria-hidden=&#34;true&#34; title=&#34;Link to this heading&#34; tabindex=&#34;-1&#34;&gt;&#xA;        &lt;svg&#xA;  xmlns=&#34;http://www.w3.org/2000/svg&#34;&#xA;  width=&#34;16&#34;&#xA;  height=&#34;16&#34;&#xA;  fill=&#34;none&#34;&#xA;  stroke=&#34;currentColor&#34;&#xA;  stroke-linecap=&#34;round&#34;&#xA;  stroke-linejoin=&#34;round&#34;&#xA;  stroke-width=&#34;2&#34;&#xA;  class=&#34;lucide lucide-link w-4 h-4 block&#34;&#xA;  viewBox=&#34;0 0 24 24&#34;&#xA;&gt;&#xA;  &lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; /&gt;&#xA;  &lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; /&gt;&#xA;&lt;/svg&gt;&#xA;&#xA;    &lt;/a&gt;&#xA;  &#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Your stats professor can say &lt;em&gt;&amp;ldquo;correlation is not causation&amp;rdquo;&lt;/em&gt; like a broken record, but we can&amp;rsquo;t help but think about causation. Even 12-month-old babies don&amp;rsquo;t think the motions of the two blocks are merely correlated. They look longer, as if &lt;em&gt;surprised&lt;/em&gt;, when we reverse the sequence (but not if the blocks don&amp;rsquo;t abide by Newton&amp;rsquo;s Third Law, in which case the event can&amp;rsquo;t be causal, &lt;a href=&#34;http://www.jfkominsky.com/demos.html&#34;&gt;Kominsky et al., 2017&lt;/a&gt;). If you&amp;rsquo;re intrigued by causal cognition, I recommend &lt;a href=&#34;https://youtu.be/q0HLci67Tr8&#34;&gt;this talk&lt;/a&gt; by Tobias Gerstenberg.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Choosing Metrics</title>
      <link>http://localhost:1313/posts/metrics/</link>
      <pubDate>Sat, 06 Nov 2021 00:00:00 +0000</pubDate><author>mycaptainmy@gmail.com (Yuan Meng)</author>
      <guid>http://localhost:1313/posts/metrics/</guid>
      <description>&lt;p&gt;&amp;lsquo;Tis the college and job application season of the year. If only schools and companies have crystal balls to see into each candidate&amp;rsquo;s future achievements, they need not interview people; since they do not have such things, SAT scores, GPA, internships, and other quantifiable metrics are used to aid decisions. Simplified metrics are by no means ideal ‚Äî As Goodhart put it (often &lt;a href=&#34;https://en.wikipedia.org/wiki/Goodhart%27s_law&#34;&gt;paraphrased&lt;/a&gt;), &amp;ldquo;When a measure becomes a metric, it ceases to be a good measure.&amp;rdquo; However, the opposite is worse: Making critical decisions based on heuristics, biases, and personal opinions.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
