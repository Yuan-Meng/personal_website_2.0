<!doctype html>
<html
  lang="en-us"
  dir="ltr"
>
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    
<link rel="stylesheet" href="http://localhost:1313/css/styles.min.30bb45eb22a875545611138569e9d0de6a7f6d840a287bda29b5f6ea87c1d2f1.css">
<meta charset="utf-8" />
<meta name="language" content="en" />
<meta name="viewport" content="width=device-width" />
<title>
    Down the Rabbit Hole: Sequential User Modeling | Yuan Meng
</title>
  <meta name="description" content=" Catch the Train of Actions Shown below is my Amazon browsing history last week. Any recommendations on what I might buy next?
Yuanâ€™s Amazon browsing history last week; distinct sessions are color-coded." />
<meta property="og:url" content="http://localhost:1313/posts/seq_user_modeling/">
  <meta property="og:site_name" content="Yuan Meng">
  <meta property="og:title" content="Down the Rabbit Hole: Sequential User Modeling">
  <meta property="og:description" content="Catch the Train of Actions Shown below is my Amazon browsing history last week. Any recommendations on what I might buy next?
Yuanâ€™s Amazon browsing history last week; distinct sessions are color-coded.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-11-12T00:00:00+00:00">


  <meta itemprop="name" content="Down the Rabbit Hole: Sequential User Modeling">
  <meta itemprop="description" content="Catch the Train of Actions Shown below is my Amazon browsing history last week. Any recommendations on what I might buy next?
Yuanâ€™s Amazon browsing history last week; distinct sessions are color-coded.">
  <meta itemprop="datePublished" content="2024-11-12T00:00:00+00:00">
  <meta itemprop="wordCount" content="1723">
  <meta itemprop="keywords" content="Recommender systems,Information retrieval">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Down the Rabbit Hole: Sequential User Modeling">
  <meta name="twitter:description" content="Catch the Train of Actions Shown below is my Amazon browsing history last week. Any recommendations on what I might buy next?
Yuanâ€™s Amazon browsing history last week; distinct sessions are color-coded.">

<link rel="canonical" href="http://localhost:1313/posts/seq_user_modeling/" />

    <link rel="stylesheet" href="/css/index.css" />


      <script src="/js/main.js" defer></script>
  

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org/",
  "@id": "http://localhost:1313/posts/seq_user_modeling/",
  "@type": "BlogPosting",
  "articleSection": [
    "Recommender systems",
    "Information retrieval"
  ],
  "author": {
    "@type": "Person",
    "email": "mycaptainmy@gmail.com",
    "name": "Yuan Meng",
    "url": "http://localhost:1313/about/"
  },
  "copyrightNotice": "Yuan Meng",
  "datePublished": "2024-11-12",
  "description": " Catch the Train of Actions Shown below is my Amazon browsing history last week. Any recommendations on what I might buy next?\nYuanâ€™s Amazon browsing history last week; distinct sessions are color-coded.",
  "headline": "Down the Rabbit Hole: Sequential User Modeling",
  "isPartOf": {
    "@id": "http://localhost:1313/posts/",
    "@type": "Blog",
    "name": "Posts"
  },
  "mainEntityOfPage": "http://localhost:1313/posts/seq_user_modeling/",
  "name": "Down the Rabbit Hole: Sequential User Modeling",
  "timeRequired": "PT9M",
  "url": "http://localhost:1313/posts/seq_user_modeling/",
  "wordCount": 1723
}
</script>


  </head>
  <body>
    <div class="container mx-auto flex max-w-prose flex-col space-y-10 p-4 md:p-6">
      <header class="flex flex-row items-center justify-between">
        <div>
  <a id="skip-nav" class="sr-only" href="#maincontent">Skip to main content</a>
  <a class="font-semibold" href="/">Yuan Meng</a>
</div>

  <nav>
    <ul class="flex flex-row items-center justify-end space-x-4">
    <li>
      <a href="/about/">About</a
      >
    </li>
    <li>
      <a aria-current="true" class="ancestor" href="/posts/">Posts</a
      >
    </li>
    <li>
      <a href="/notes/">Notes</a
      >
    </li>
    </ul>
  </nav>


      </header>
      <main class="prose prose-slate relative md:prose-lg prose-h1:text-[2em]" id="maincontent">
        <article class="main">
    <header>
      <h1 class="!mb-1">Down the Rabbit Hole: Sequential User Modeling</h1><div class="flex flex-row items-center space-x-4">
          <time class="text-sm italic opacity-80" datetime="2024-11-12T00:00:00&#43;00:00">November 12, 2024</time>
        </div>
    </header>

    
    Reading time: 9 minutes

    
    
      <div class="toc-container">
        <span id="toc-toggle">
          <span id="toc-icon">â–¶</span> 
          <span>Table of Contents</span>
        </span>
        <nav id="TableOfContents" class="toc-content">
          <nav id="TableOfContents">
  <ul>
    <li><a href="#catch-the-train-of-actions">Catch the Train of Actions</a></li>
    <li><a href="#flavors-of-sequence-modeling">Flavors of Sequence Modeling</a>
      <ul>
        <li><a href="#pre-transformer">Pre-Transformer</a>
          <ul>
            <li><a href="#markov-chains">Markov Chains</a></li>
            <li><a href="#recurrent-neural-networks">Recurrent Neural Networks</a></li>
            <li><a href="#convolutional-neural-networks">Convolutional Neural Networks</a></li>
            <li><a href="#graph-neural-networks">Graph Neural Networks</a></li>
          </ul>
        </li>
        <li><a href="#target-attention">Target Attention</a>
          <ul>
            <li><a href="#one-stage-din-family">One-Stage: DIN Family</a></li>
            <li><a href="#two-stage-gsu--esu">Two-Stage: GSU + ESU</a></li>
          </ul>
        </li>
        <li><a href="#language-modeling">&ldquo;Language Modeling&rdquo;</a>
          <ul>
            <li><a href="#masked-action-modeling">Masked Action Modeling</a></li>
            <li><a href="#next-action-prediction">Next-Action Prediction</a></li>
          </ul>
        </li>
        <li><a href="#is-attention-what-you-need">Is Attention What You Need?</a>
          <ul>
            <li><a href="#google-convformer">Google: ConvFormer</a></li>
            <li><a href="#meta-hstu">Meta: HSTU</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#code-examples">Code Examples</a>
      <ul>
        <li><a href="#din-alibaba-2017">DIN (Alibaba, 2017)</a></li>
        <li><a href="#transact-pinterest-2023">TransAct (Pinterest, 2023)</a></li>
      </ul>
    </li>
    <li><a href="#references">References</a>
      <ul>
        <li><a href="#overview--collections">Overview &amp; Collections</a></li>
        <li><a href="#approach-target-attention">Approach: Target Attention</a></li>
        <li><a href="#approach-language-modeling">Approach: Language Modeling</a></li>
        <li><a href="#approach-beyond-attention">Approach: Beyond Attention</a></li>
      </ul>
    </li>
  </ul>
</nav>
        </nav>
      </div>

      <script>
        
        document.addEventListener('DOMContentLoaded', function () {
          var tocToggle = document.getElementById('toc-toggle');
          var tocContent = document.getElementById('TableOfContents');
          var tocIcon = document.getElementById('toc-icon');
          tocToggle.addEventListener('click', function () {
            if (tocContent.style.display === 'none' || tocContent.style.display === '') {
              tocContent.style.display = 'block';
              tocIcon.textContent = 'â–¼'; 
            } else {
              tocContent.style.display = 'none';
              tocIcon.textContent = 'â–¶'; 
            }
          });
        });
      </script>
    

    
    <div class="content">
      <h2 id="catch-the-train-of-actions" class="scroll-mt-8 group">
  Catch the Train of Actions
  
    <a href="#catch-the-train-of-actions"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h2>
<p>Shown below is my Amazon browsing history last week. Any recommendations on what I might buy next?</p>
<figure><img src="https://www.dropbox.com/scl/fi/t3fs6pgs8rxlysnpoqeq9/Screenshot-2024-11-11-at-4.25.33-PM.png?rlkey=kv37yorsm6qdlro4y4ot496s8&amp;st=p200ep0j&amp;raw=1"
    alt="Yuan&rsquo;s Amazon browsing history last week; distinct sessions are color-coded." width="1800"><figcaption>
      <p>Yuan&rsquo;s Amazon browsing history last week; distinct sessions are color-coded.</p>
    </figcaption>
</figure>

<p>A model performing average/sum pooling over engaged items may recommend books, cleaning supplies, or blue shampoos &mdash; these were the items I engaged the most with and align with my long-term interests in tidiness, reading, and paying punk homage. But in this session, I want more pull-up bar recommendations as I&rsquo;m comparing options. After that, I may wanna look at more fitness accessories&hellip;</p>
<p>Rather than treating engaged items as a <em>static</em>, <em>unordered</em> collection, sequential user modeling traces the train of action sequences to predict the next action, adapting to evolving, dynamic user interests.</p>
<h2 id="flavors-of-sequence-modeling" class="scroll-mt-8 group">
  Flavors of Sequence Modeling
  
    <a href="#flavors-of-sequence-modeling"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h2>
<p>Sequential user modeling can be framed as a next-item-prediction problem: <span style="background-color: #abe0bb">given a user&rsquo;s action sequence $S = \{i_1, \ldots, i_L\}$ and a target item $i_t$, output a utility score for the item $p(i_t|i_{i:L})$</span>. Each interaction $i_j$ consists of a $\langle \mathrm{user}, \mathrm{action}, \mathrm{item} \rangle$ triple, where the action could be a click, an add-to-cart, a conversion, or other meaningful engagements with recommended or sponsored content.</p>
<p>Any methods suitable for modeling sequences (e.g., tokens in language, pixels in images, genes in DNAs) can be applied to this problem, from Markov chains, RNNs, CNNs, and GNNs that pre-date Transformers, to the Transformer architecture (whether using only the attention mechanism or the full encoder) adapted to recommender systems (see <a href="https://arxiv.org/abs/2001.04830">Wang et al. 2019</a> for a comprehensive review).</p>
<figure><img src="https://www.dropbox.com/scl/fi/bo2lmx0zswr9ntdlofs0c/Screenshot-2024-11-12-at-12.10.38-AM.png?rlkey=d3cmaxh5i1dckdnonvczfwm7i&amp;st=vmlrlwvc&amp;raw=1"
    alt="An overview of classic sequential user modeling methods (Wang et al., 2019)." width="600"><figcaption>
      <p>An overview of classic sequential user modeling methods (<a href="https://arxiv.org/abs/2001.04830">Wang et al., 2019</a>).</p>
    </figcaption>
</figure>

<p>One thing I find interesting (but also expected) is that, since sequential user modeling borrows heavily from natural language processing (NLP), the evolution of the former closely follows that of the latter.</p>
<h3 id="pre-transformer" class="scroll-mt-8 group">
  Pre-Transformer
  
    <a href="#pre-transformer"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<h4 id="markov-chains" class="scroll-mt-8 group">
  Markov Chains
  
    <a href="#markov-chains"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<p>In his <a href="http://cm.bell-labs.com/cm/ms/what/shannonday/shannon1948.pdf"><em>A Mathematical Theory of Communication</em></a> that laid the foundation for information theory, <span class="sidenote">
  <input
    aria-label="Show sidenote"
    type="checkbox"
    id="sidenote-checkbox-03"
    class="sidenote-checkbox hidden"
  />
  <label
    tabindex="0"
    role="mark"
    aria-details="sidenote-03"
    for="sidenote-checkbox-03"
    class="sidenote-mark"
    >Claude</label
  >
  <small id="sidenote-03" class="sidenote-content">
    <span class="sr-only"> (sidenote: </span>it only dawned on me after a year that Anthropic's Claude is named after Shannon.<span class="sr-only">)</span>
  </small>
</span>
 Shannon used a <a href="https://www.cs.princeton.edu/courses/archive/spr05/cos126/assignments/markov.html">Markov chain</a> model to predict the transitional probability from one alphabet to another as an attempt to model natural language. The toy implementation below defines state transitions and randomly selects the next states to generate sequences. Transitional probabilities can be learned.</p>
<figure class="codeblock not-prose relative scroll-mt-8" id="codeblock-01">
  <aside
    class="absolute right-0 top-0 hidden rounded-bl-sm rounded-tr-sm bg-white/10 px-2 py-1 text-white/70 transition-opacity md:inline-block"
  >
    <div class="codeblock-meta flex max-w-xs flex-row items-center space-x-3">
      <div class="small-caps shrink cursor-default truncate font-mono text-xs" aria-hidden="true">
        <span class="relative">python3</span>
      </div>
      <div>
        <clipboard-copy
          type="button"
          aria-label="Copy code to clipboard"
          title="Copy code to clipboard"
          class="block cursor-pointer transition-colors hover:text-sky-400"
          target="#codeblock-01 code"
        >
          <svg
  xmlns="http://www.w3.org/2000/svg"
  fill="none"
  stroke="currentColor"
  stroke-width="2"
  stroke-linecap="round"
  stroke-linejoin="round"
  class="lucide lucide-clipboard h-4 w-4"
  viewBox="0 0 24 24"
>
  <rect width="8" height="4" x="8" y="2" rx="1" ry="1" />
  <path d="M16 4h2a2 2 0 0 1 2 2v14a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V6a2 2 0 0 1 2-2h2" />
</svg>

        </clipboard-copy>
      </div>
      <div>
        <a
          href="#codeblock-01"
          class="block"
          aria-label="Link to this code block"
          title="Link to this code block"
        >
          <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

        </a>
      </div>
    </div>
  </aside>
  <p class="sr-only">python3 code snippet start</p>
  <div class="highlight"><div style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python3" data-lang="python3"><span style="display:flex;"><span><span style="color:#ff79c6">class</span> <span style="color:#50fa7b">MarkovChain</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4"># dictionary to store transitions: {current state : [next state]}</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#ff79c6">.</span>transitions <span style="color:#ff79c6">=</span> {}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">def</span> <span style="color:#50fa7b">addTransition</span>(self, v, w):
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4"># add a transition from state v to state w</span>
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">if</span> v <span style="color:#ff79c6">not</span> <span style="color:#ff79c6">in</span> self<span style="color:#ff79c6">.</span>transitions:
</span></span><span style="display:flex;"><span>            self<span style="color:#ff79c6">.</span>transitions[v] <span style="color:#ff79c6">=</span> []
</span></span><span style="display:flex;"><span>        self<span style="color:#ff79c6">.</span>transitions[v]<span style="color:#ff79c6">.</span>append(w)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">def</span> <span style="color:#50fa7b">next</span>(self, v):
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4"># pick a transition leaving state v uniformly at random</span>
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">if</span> v <span style="color:#ff79c6">not</span> <span style="color:#ff79c6">in</span> self<span style="color:#ff79c6">.</span>transitions <span style="color:#ff79c6">or</span> <span style="color:#ff79c6">not</span> self<span style="color:#ff79c6">.</span>transitions[v]:
</span></span><span style="display:flex;"><span>            <span style="color:#ff79c6">return</span> <span style="color:#ff79c6">None</span>  <span style="color:#6272a4"># no transitions available</span>
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">return</span> random<span style="color:#ff79c6">.</span>choice(self<span style="color:#ff79c6">.</span>transitions[v])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">def</span> <span style="color:#50fa7b">toString</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4"># return a string representation of the Markov chain</span>
</span></span><span style="display:flex;"><span>        result <span style="color:#ff79c6">=</span> []
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">for</span> state, transitions <span style="color:#ff79c6">in</span> self<span style="color:#ff79c6">.</span>transitions<span style="color:#ff79c6">.</span>items():
</span></span><span style="display:flex;"><span>            result<span style="color:#ff79c6">.</span>append(<span style="color:#f1fa8c">f</span><span style="color:#f1fa8c">&#34;</span><span style="color:#f1fa8c">{</span>state<span style="color:#f1fa8c">}</span><span style="color:#f1fa8c"> -&gt; </span><span style="color:#f1fa8c">{</span><span style="color:#f1fa8c">&#39;, &#39;</span><span style="color:#ff79c6">.</span>join(transitions)<span style="color:#f1fa8c">}</span><span style="color:#f1fa8c">&#34;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">return</span> <span style="color:#f1fa8c">&#34;</span><span style="color:#f1fa8c">\n</span><span style="color:#f1fa8c">&#34;</span><span style="color:#ff79c6">.</span>join(result)</span></span></code></pre></td></tr></table>
</div>
</div>
  <p class="sr-only">python3 code snippet end</p>

  
</figure>
<p>A Markov-chain recommender predicts the transition probability from one action sequence ($S = \{\mathrm{printer}, \mathrm{ink}\}$) to another ($S = \{\mathrm{printer}, \mathrm{ink}, \mathrm{paper}\}$), either directly (e.g., <a href="https://arxiv.org/abs/1303.0665">Garcin et al., 2013</a>) or by embedding Markov chains into a latent space to compute transitional probabilities based on Euclidean distances (e.g., <a href="https://www.ijcai.org/Proceedings/15/Papers/293.pdf">Feng et al., 2015</a>).</p>
<figure><img src="https://www.dropbox.com/scl/fi/pgjlb1nee84lihensin30/Screenshot-2024-11-12-at-12.59.47-PM.png?rlkey=a43d16ssyuhjjtxmzyldqawpu&amp;st=nfyg4npx&amp;raw=1"
    alt="Markov chains recommend items by transition probabilities (Feng et al., 2015)." width="600"><figcaption>
      <p>Markov chains recommend items by transition probabilities (<a href="https://www.ijcai.org/Proceedings/15/Papers/293.pdf">Feng et al., 2015</a>).</p>
    </figcaption>
</figure>

<p>A fatal shortcoming of Markov chains lies in the <a href="https://en.wikipedia.org/wiki/Memorylessness">&ldquo;memorylessness&rdquo;</a> assumption &mdash; that future states depend only on the current state, ignoring preceding states. For example, if I bought cat food (because I suddenly remembered ðŸ˜‚) after buying ink, the system won&rsquo;t be more likely to recommend paper to me than if I didn&rsquo;t buy ink at all. Real shoppers jump between diverse interests and engage with unrelated items, which are nuances that Markov chains cannot capture.</p>
<h4 id="recurrent-neural-networks" class="scroll-mt-8 group">
  Recurrent Neural Networks
  
    <a href="#recurrent-neural-networks"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<p>Instead of relying solely on today&rsquo;s input to predict tomorrow, a Recurrent Neural Network (RNN) maintains a &ldquo;hidden state&rdquo; that serves as a memory of yesterday&rsquo;s activation and that of all days prior. The hidden state is &ldquo;hidden&rdquo; because it doesn&rsquo;t produce any observable output, such as a character or an action. Today&rsquo;s input, combined with the previous hidden state, is used to predict tomorrow. The last hidden state can be used to represent the sequence so far.</p>
<figure><img src="https://www.dropbox.com/scl/fi/r05faxbpxpevzgtjywz2m/Screenshot-2024-11-12-at-7.18.01-PM.png?rlkey=1p88m4grpfp1imww83d9lf8vx&amp;st=nbyecz33&amp;raw=1"
    alt="The vanilla RNN architecture that almost nobody uses directly (Wikipedia)." width="1800"><figcaption>
      <p>The vanilla RNN architecture that almost nobody uses directly (<a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">Wikipedia</a>).</p>
    </figcaption>
</figure>

<p>Generally speaking, a RNN maps the input and the hidden state at step $t$, $x_t$ and $h_t$, to an output $y_t$ and an updated hidden state $h_{t+1}$,</p>
<p>$$
f_{\theta}(x_t, h_t) \rightarrow (y_t, h_{t+1}),
$$</p>
<p>where:</p>
<ul>
<li>$x_t$: input vector;</li>
<li>$h_t$: hidden vector;</li>
<li>$y_t$: output vector;</li>
<li>$\theta$: neural network parameters.</li>
</ul>
<p>Vanilla RNNs are difficult to train because they are susceptible to the vanishing or exploding gradient problem, where gradients become increasingly small or large when we are backpropagating errors from the last output to the first input. More advanced versions RNNs, such as <a href="https://en.wikipedia.org/wiki/Long_short-term_memory">Long Short-Term Memory (LSTM)</a> and <a href="https://en.wikipedia.org/wiki/Gated_recurrent_unit">Gated Recurrent Units (GRUs)</a>, were invented to address these issues. From the early 2010s until the rise of Transformers around 2017-2018, these RNN variants were state-of-the-art in Natural Language Processing (NLP).</p>
<p><a href="https://research.google/pubs/recurrent-recommender-networks/">Wu et al. (2017)</a> introduced the Recurrent Recommender Network (RRN), using LSTMs to encode user and movie hidden states, which then help predict how a user might rate a movie at a given time. RRN outperformed <a href="https://en.wikipedia.org/wiki/Matrix_factorization_(recommender_systems)">Matrix Factorization</a> methods such SVD++, which won the Netflix Prize but ignored the temporal dynamics of users and movies. The idea is based on a few clever observations:</p>
<ul>
<li><strong>Users evolve with movies and over time</strong>: After watching a great detective movie like <em>Knives Out</em>, I want to see more like it; as I grow older, I appreciate non-action movies more&hellip;</li>
<li><strong>Movies evolve with audiences and over time</strong>: Every Christmas, <em>Elf</em> sees a resurgence in popularity; winning an award often leads to a sudden spike in appreciation for a film; some &ldquo;sleeper hits&rdquo; take years to build a reputation..</li>
</ul>
<figure><img src="https://www.dropbox.com/scl/fi/qn3dzi4d7ajmmvbc9xgru/Screenshot-2024-11-12-at-9.15.11-PM.png?rlkey=mrud07o647yakehuf7cxw87rq&amp;st=syacksj8&amp;raw=1"
    alt="RRN uses 2 LTSMs to capture user and movie hidden states (Wu et al., 2017)." width="1800"><figcaption>
      <p>RRN uses 2 LTSMs to capture user and movie hidden states (<a href="https://research.google/pubs/recurrent-recommender-networks/">Wu et al., 2017</a>).</p>
    </figcaption>
</figure>

<p>The authors used one LSTM to model user hidden states and another to model movie hidden states. A time $t$, the predicted rating of user $i$ on movie $j$, $\hat{r}_{ij|t}$, is a combination the user&rsquo;s and the movie&rsquo;s dynamic latent factors (the last hidden states of the LTSMs) and their stationary latent factors (representing stable user and movie traits),</p>
<p>$$
\hat{r}_{ij|t} = f(u_{it}, m_{jt}, u_i, m_j) := \langle \tilde{u}_{it}, \tilde{m}_{jt} \rangle + \langle u_i, m_j \rangle,
$$</p>
<p>where $\langle \cdot, \cdot \rangle$ denotes an inner product, and:</p>
<ul>
<li>$\tilde{u}_{it}$ and $\tilde{m}_{jt}$ are time-varying states $u_{it}$ (for the user) and $m_{jt}$ (for the movie) generated by the LSTM networks;</li>
<li>$u_i$ and $m_j$ are stationary latent factors for the user (e,.g., profile, long-term interests) and the movie (e.g., genre), respectively.</li>
</ul>
<p>The model is trained to minimize the error between the predicted rating $\hat{r}_{ij|t}$ and the actual rating $r_{ij|t}$. It captures exogenous dynamics (e.g., winning an award) and endogenous dynamics (e.g., seasonality) of movies more effectively than models that don&rsquo;t take account of temporal information.</p>
<p>LTSMs in RRN can be replaced with other RNN variants, such as GRUs (e.g., <a href="https://arxiv.org/abs/1511.06939">Hidasi et al., 2016</a>) and hierarchical RNNs (e.g., <a href="https://dl.acm.org/doi/abs/10.1145/3109859.3109896">Quadrana et al., 2017</a>). Regardless of the specific architecture, RNN-based recommenders share some common drawbacks:</p>
<ul>
<li><strong>False dependencies</strong>: Just because I bought cat litter after buying books doesn&rsquo;t mean the two are related. User action sequences contain lots of noise, which RNNs cannot sift through;</li>
<li><strong>Ignoring collective dependencies</strong>: Multiple past actions can collectively predict a future action. For example, after buying rum and mint, it makes sense to guess I&rsquo;m making a Mojito and recommend lime juice, but not if I just bought one of them.</li>
</ul>
<h4 id="convolutional-neural-networks" class="scroll-mt-8 group">
  Convolutional Neural Networks
  
    <a href="#convolutional-neural-networks"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<p>Convolutional Neural Networks (CNNs) were initially developed for Computer Vision (CV), where they excel at extracting local patterns (for more details, see my <a href="https://www.yuan-meng.com/posts/human_vision/#convolutional-neural-network-cnn">post</a>). Since a sequence can be represented as a 1D image or that item embeddings can be stacked into a matrix (a 2D image), CNNs can also be used to model sequential data.</p>
<!-- ([Tang et al., 2018](https://dl.acm.org/doi/abs/10.1145/3159652.3159656))
([Yuan et al., 2019])(https://dl.acm.org/doi/abs/10.1145/3289600.3290975) -->
<h4 id="graph-neural-networks" class="scroll-mt-8 group">
  Graph Neural Networks
  
    <a href="#graph-neural-networks"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<h3 id="target-attention" class="scroll-mt-8 group">
  Target Attention
  
    <a href="#target-attention"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<!-- DIN started the target attention traditional. general idea is different items play different roles for the same target.  -->
<h4 id="one-stage-din-family" class="scroll-mt-8 group">
  One-Stage: DIN Family
  
    <a href="#one-stage-din-family"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<h4 id="two-stage-gsu--esu" class="scroll-mt-8 group">
  Two-Stage: GSU + ESU
  
    <a href="#two-stage-gsu--esu"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<h3 id="language-modeling" class="scroll-mt-8 group">
  &ldquo;Language Modeling&rdquo;
  
    <a href="#language-modeling"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<h4 id="masked-action-modeling" class="scroll-mt-8 group">
  Masked Action Modeling
  
    <a href="#masked-action-modeling"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<h4 id="next-action-prediction" class="scroll-mt-8 group">
  Next-Action Prediction
  
    <a href="#next-action-prediction"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<!-- BERT-style models. 
Q: why not GPT style w/ causal mask, which is more natural for future prediction? -->
<h3 id="is-attention-what-you-need" class="scroll-mt-8 group">
  Is Attention What You Need?
  
    <a href="#is-attention-what-you-need"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<blockquote>
<p>The efficacy of model simplification often hinges on precise prior knowledge, prompting an inquiry into why certain simplifications to the Transformer architecture prove effective and what insights they offer. &mdash; Wang et al., <a href="https://openreview.net/forum?id=Gny0PVtKz2"><em>ICLR 2024</em></a></p>
</blockquote>
<h4 id="google-convformer" class="scroll-mt-8 group">
  Google: ConvFormer
  
    <a href="#google-convformer"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<h4 id="meta-hstu" class="scroll-mt-8 group">
  Meta: HSTU
  
    <a href="#meta-hstu"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<!-- Meta and Google => strip away parts of Transformers -->
<hr>
<h2 id="code-examples" class="scroll-mt-8 group">
  Code Examples
  
    <a href="#code-examples"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h2>
<h3 id="din-alibaba-2017" class="scroll-mt-8 group">
  DIN (Alibaba, 2017)
  
    <a href="#din-alibaba-2017"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<h3 id="transact-pinterest-2023" class="scroll-mt-8 group">
  TransAct (Pinterest, 2023)
  
    <a href="#transact-pinterest-2023"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<p><a href="https://github.com/pinterest/transformer_user_action">repo</a></p>
<hr>
<h2 id="references" class="scroll-mt-8 group">
  References
  
    <a href="#references"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h2>
<h3 id="overview--collections" class="scroll-mt-8 group">
  Overview &amp; Collections
  
    <a href="#overview--collections"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<ol>
<li>&ldquo;Old&rdquo; but popular lit review ðŸ‘‰ <a href="https://arxiv.org/abs/2001.04830"><em>Sequential Recommender Systems: Challenges, Progress and Prospects</em></a> (2019) by Wang et al., <em>IJCAI</em>.</li>
<li>A Meta MLE&rsquo;s awesome post ðŸ‘‰ <a href="https://mlfrontiers.substack.com/p/user-action-sequence-modeling-from"><em>User Action Sequence Modeling: From Attention to Transformers and Beyond</em></a></li>
<li>GitHub repos of sequential user modeling ðŸ‘‰ papers (<a href="https://github.com/HqWu-HITCS/Awesome-Sequence-Modeling-for-Recommendation">Awesome-Sequence-Modeling-for-Recommendation</a>) + code (<a href="https://github.com/reczoo/FuxiCTR">FuxiCTR</a>)</li>
</ol>
<h3 id="approach-target-attention" class="scroll-mt-8 group">
  Approach: Target Attention
  
    <a href="#approach-target-attention"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<ol start="4">
<li>
<p>Overview: <a href="https://mlfrontiers.substack.com/p/target-attention-is-all-you-need"><em>Target Attention Is All You Need: Modeling Extremely Long User Action Sequences in Recommender Systems</em></a> by Samuel Flender.</p>
</li>
<li>
<p>The OG architecture ðŸ‘‰ DIN: <a href="https://arxiv.org/abs/1706.06978"><em>Deep Interest Network for Click-Through Rate Prediction</em></a> (2017) by Zhou et al., <em>KDD</em>.</p>
<ul>
<li>And its many a Alibaba siblings: <a href="https://arxiv.org/abs/1809.03672">DIEN (2018)</a>, <a href="https://arxiv.org/abs/1905.06482">DSIN (2019)</a>, <a href="https://arxiv.org/abs/2005.12981">DHAN (2020)</a>, <a href="https://dl.acm.org/doi/abs/10.1145/3340531.3412092">DMIN (2020)</a>, <a href="https://arxiv.org/abs/2409.02425">DAIN (2024)</a>, &hellip;</li>
</ul>
</li>
<li>
<p>Go crazy on sequence length ðŸ‘‰ SIM: <a href="https://arxiv.org/abs/2006.05639"><em>Search-based User Interest Modeling with Lifelong Sequential Behavior Data for Click-Through Rate Prediction</em></a> (2020) by Qi et al., <em>CIKM</em>.</p>
<ul>
<li>Ultra long: <a href="https://arxiv.org/abs/2108.04468">ETA (2021)</a>, <a href="https://arxiv.org/abs/2302.02352">TWIN (2023)</a>, <a href="https://arxiv.org/html/2407.16357v1">TWIN-v2 (2024)</a>, &hellip;</li>
<li>Review post: <a href="https://mlfrontiers.substack.com/p/towards-life-long-user-history-modeling"><em>Towards Life-Long User History Modeling in Recommender Systems</em></a> by Samuel Flender.</li>
</ul>
</li>
<li>
<p>Squeeze every ounce of sequences ðŸ‘‰ TIM: <a href="2024"><em>Ads Recommendation in a Collapsed and Entangled World</em></a> by Pan et al, <em>KDD</em>.</p>
<ul>
<li>Paper summary: <a href="https://mlfrontiers.substack.com/p/breaking-down-tencents-recommendation"><em>Breaking down Tencent&rsquo;s Recommendation Algorithm</em></a> by Samuel Flender.</li>
</ul>
</li>
</ol>
<h3 id="approach-language-modeling" class="scroll-mt-8 group">
  Approach: Language Modeling
  
    <a href="#approach-language-modeling"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<ol start="8">
<li>The OG ðŸ‘‰ <a href="https://arxiv.org/abs/1904.06690"><em>BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer</em></a> (2019) by Sun et al., <em>CIKM</em>.</li>
<li>Play with objectives ðŸ‘‰ <a href="https://arxiv.org/abs/2205.04507"><em>PinnerFormer: Sequence Modeling for User Representation at Pinterest</em></a> (2022) by Pancha et al., <em>KDD</em>.</li>
<li>Capture short-term interests ðŸ‘‰ <a href="https://arxiv.org/abs/2306.00248"><em>TransAct: Transformer-based Realtime User Action Model for Recommendation at Pinterest</em></a> (2024) by Xia et al., <em>KDD</em>.</li>
<li>Applications at Pinterest ðŸ‘‰ organic ranking (<a href="https://medium.com/pinterest-engineering/large-scale-user-sequences-at-pinterest-78a5075a3fe9"><em>Large-scale User Sequences at Pinterest</em></a>) + ads ranking (<a href="https://medium.com/pinterest-engineering/user-action-sequence-modeling-for-pinterest-ads-engagement-modeling-21139cab8f4e"><em>User Action Sequence Modeling for Pinterest Ads Engagement Modeling</em></a>)</li>
</ol>
<h3 id="approach-beyond-attention" class="scroll-mt-8 group">
  Approach: Beyond Attention
  
    <a href="#approach-beyond-attention"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<ol start="12">
<li>Meta AI ðŸ‘‰ <a href="https://arxiv.org/abs/2402.17152"><em>Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations</em></a> (2024) by Zhai et al., <em>ICML</em>.</li>
<li>Google Research ðŸ‘‰ <a href="https://openreview.net/forum?id=Gny0PVtKz2"><em>ConvFormer: Revisiting Token-mixers for Sequential User Modeling</em></a> (2024) by Wang et al., <em>ICLR</em>.</li>
</ol>
    </div>
  </article>

  
    <aside class="not-prose flex flex-col space-y-8 border-t pt-6">
    <section class="flex flex-col space-y-4">
      <h2 class="flex flex-row items-center space-x-2 text-lg font-semibold">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-shapes h-4 w-4"
  viewBox="0 0 24 24"
  aria-hidden="true"
>
  <path
    d="M8.3 10a.7.7 0 0 1-.626-1.079L11.4 3a.7.7 0 0 1 1.198-.043L16.3 8.9a.7.7 0 0 1-.572 1.1Z"
  />
  <rect width="7" height="7" x="3" y="14" rx="1" />
  <circle cx="17.5" cy="17.5" r="3.5" />
</svg>

        <span>Categories</span>
      </h2>

      <ul class="ml-6 flex flex-row flex-wrap items-center space-x-2">
          <li>
            <a href="/categories/recommender-systems/" class="taxonomy category">recommender systems</a>
          </li>
          <li>
            <a href="/categories/information-retrieval/" class="taxonomy category">information retrieval</a>
          </li>
      </ul>
    </section>
    <section class="flex flex-col space-y-4" aria-hidden="true">
      <h2 class="flex flex-row items-center space-x-2 text-lg font-semibold">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-chart-network h-4 w-4"
  viewBox="0 0 24 24"
  aria-hidden="true"
>
  <path
    d="m13.11 7.664 1.78 2.672M14.162 12.788l-3.324 1.424M20 4l-6.06 1.515M3 3v16a2 2 0 0 0 2 2h16"
  />
  <circle cx="12" cy="6" r="2" />
  <circle cx="16" cy="12" r="2" />
  <circle cx="9" cy="15" r="2" />
</svg>

        <span>Graph</span>
      </h2>

      <content-network-graph
  class="h-64 ml-6"
  data-endpoint="/graph/index.json"
  page="/posts/seq_user_modeling/"
></content-network-graph>

    </section>
</aside>


      </main>
      <footer class="mt-20 border-t border-neutral-100 pt-2 text-xs">
        
<section class="items-top flex flex-row justify-between opacity-70">
  <div class="flex flex-col space-y-2">
      <p>Copyright &copy; 2024, Yuan Meng.</p>
      <div
        xmlns:cc="https://creativecommons.org/ns#"
        xmlns:dct="http://purl.org/dc/terms/"
        about="https://creativecommons.org"
      >
        Content is available under
        <a href="https://creativecommons.org/licenses/by-sa/4.0/" rel="license" class="inline-block" title="Creative Commons Attribution-ShareAlike 4.0 International"
          >CC BY-SA 4.0</a
        >
        unless otherwise noted.
      </div>
        <div
          class="mt-2 flex items-center space-x-2 fill-slate-400 hover:fill-slate-600 motion-safe:transition-colors"
        >
          <div class="flex-none cursor-help"><svg
  version="1.0"
  xmlns="http://www.w3.org/2000/svg"
  viewBox="5.5 -3.5 64 64"
  xml:space="preserve"
  class="w-5 h-5 block"
  aria-hidden="true"
>
  <title>Creative Commons</title>
  <circle fill="transparent" cx="37.785" cy="28.501" r="28.836" />
  <path
    d="M37.441-3.5c8.951 0 16.572 3.125 22.857 9.372 3.008 3.009 5.295 6.448 6.857 10.314 1.561 3.867 2.344 7.971 2.344 12.314 0 4.381-.773 8.486-2.314 12.313-1.543 3.828-3.82 7.21-6.828 10.143-3.123 3.085-6.666 5.448-10.629 7.086-3.961 1.638-8.057 2.457-12.285 2.457s-8.276-.808-12.143-2.429c-3.866-1.618-7.333-3.961-10.4-7.027-3.067-3.066-5.4-6.524-7-10.372S5.5 32.767 5.5 28.5c0-4.229.809-8.295 2.428-12.2 1.619-3.905 3.972-7.4 7.057-10.486C21.08-.394 28.565-3.5 37.441-3.5zm.116 5.772c-7.314 0-13.467 2.553-18.458 7.657-2.515 2.553-4.448 5.419-5.8 8.6a25.204 25.204 0 0 0-2.029 9.972c0 3.429.675 6.734 2.029 9.913 1.353 3.183 3.285 6.021 5.8 8.516 2.514 2.496 5.351 4.399 8.515 5.715a25.652 25.652 0 0 0 9.943 1.971c3.428 0 6.75-.665 9.973-1.999 3.219-1.335 6.121-3.257 8.713-5.771 4.99-4.876 7.484-10.99 7.484-18.344 0-3.543-.648-6.895-1.943-10.057-1.293-3.162-3.18-5.98-5.654-8.458-5.146-5.143-11.335-7.715-18.573-7.715zm-.401 20.915-4.287 2.229c-.458-.951-1.019-1.619-1.685-2-.667-.38-1.286-.571-1.858-.571-2.856 0-4.286 1.885-4.286 5.657 0 1.714.362 3.084 1.085 4.113.724 1.029 1.791 1.544 3.201 1.544 1.867 0 3.181-.915 3.944-2.743l3.942 2c-.838 1.563-2 2.791-3.486 3.686-1.484.896-3.123 1.343-4.914 1.343-2.857 0-5.163-.875-6.915-2.629-1.752-1.752-2.628-4.19-2.628-7.313 0-3.048.886-5.466 2.657-7.257 1.771-1.79 4.009-2.686 6.715-2.686 3.963-.002 6.8 1.541 8.515 4.627zm18.457 0-4.229 2.229c-.457-.951-1.02-1.619-1.686-2-.668-.38-1.307-.571-1.914-.571-2.857 0-4.287 1.885-4.287 5.657 0 1.714.363 3.084 1.086 4.113.723 1.029 1.789 1.544 3.201 1.544 1.865 0 3.18-.915 3.941-2.743l4 2c-.875 1.563-2.057 2.791-3.541 3.686a9.233 9.233 0 0 1-4.857 1.343c-2.896 0-5.209-.875-6.941-2.629-1.736-1.752-2.602-4.19-2.602-7.313 0-3.048.885-5.466 2.658-7.257 1.77-1.79 4.008-2.686 6.713-2.686 3.962-.002 6.783 1.541 8.458 4.627z"
  />
</svg>
</div><div class="flex-none cursor-help"><svg
  version="1.0"
  xmlns="http://www.w3.org/2000/svg"
  viewBox="5.5 -3.5 64 64"
  xml:space="preserve"
  class="w-5 h-5 block"
>
  <title>Credit must be given to the creator</title>
  <circle fill="transparent" cx="37.637" cy="28.806" r="28.276" />
  <path
    d="M37.443-3.5c8.988 0 16.57 3.085 22.742 9.257C66.393 11.967 69.5 19.548 69.5 28.5c0 8.991-3.049 16.476-9.145 22.456-6.476 6.363-14.113 9.544-22.912 9.544-8.649 0-16.153-3.144-22.514-9.43C8.644 44.784 5.5 37.262 5.5 28.5c0-8.761 3.144-16.342 9.429-22.742C21.101-.415 28.604-3.5 37.443-3.5zm.114 5.772c-7.276 0-13.428 2.553-18.457 7.657-5.22 5.334-7.829 11.525-7.829 18.572 0 7.086 2.59 13.22 7.77 18.398 5.181 5.182 11.352 7.771 18.514 7.771 7.123 0 13.334-2.607 18.629-7.828 5.029-4.838 7.543-10.952 7.543-18.343 0-7.276-2.553-13.465-7.656-18.571-5.104-5.104-11.276-7.656-18.514-7.656zm8.572 18.285v13.085h-3.656v15.542h-9.944V33.643h-3.656V20.557c0-.572.2-1.057.599-1.457.401-.399.887-.6 1.457-.6h13.144c.533 0 1.01.2 1.428.6.417.4.628.886.628 1.457zm-13.087-8.228c0-3.008 1.485-4.514 4.458-4.514s4.457 1.504 4.457 4.514c0 2.971-1.486 4.457-4.457 4.457s-4.458-1.486-4.458-4.457z"
  />
</svg>
</div><div class="flex-none cursor-help"><svg
  version="1.0"
  xmlns="http://www.w3.org/2000/svg"
  viewBox="5.5 -3.5 64 64"
  xml:space="preserve"
  class="w-5 h-5 block"
>
  <title>Adaptations must be shared under the same terms</title>
  <circle fill="transparent" cx="36.944" cy="28.631" r="29.105" />
  <path
    d="M37.443-3.5c8.951 0 16.531 3.105 22.742 9.315C66.393 11.987 69.5 19.548 69.5 28.5c0 8.954-3.049 16.457-9.145 22.514-6.437 6.324-14.076 9.486-22.912 9.486-8.649 0-16.153-3.143-22.514-9.429C8.644 44.786 5.5 37.264 5.5 28.501c0-8.723 3.144-16.285 9.429-22.685C21.138-.395 28.643-3.5 37.443-3.5zm.114 5.772c-7.276 0-13.428 2.572-18.457 7.715-5.22 5.296-7.829 11.467-7.829 18.513 0 7.125 2.59 13.257 7.77 18.4 5.181 5.182 11.352 7.771 18.514 7.771 7.123 0 13.334-2.609 18.629-7.828 5.029-4.876 7.543-10.99 7.543-18.343 0-7.313-2.553-13.485-7.656-18.513-5.067-5.145-11.239-7.715-18.514-7.715zM23.271 23.985c.609-3.924 2.189-6.962 4.742-9.114 2.552-2.152 5.656-3.228 9.314-3.228 5.027 0 9.029 1.62 12 4.856 2.971 3.238 4.457 7.391 4.457 12.457 0 4.915-1.543 9-4.627 12.256-3.088 3.256-7.086 4.886-12.002 4.886-3.619 0-6.743-1.085-9.371-3.257-2.629-2.172-4.209-5.257-4.743-9.257H31.1c.19 3.886 2.533 5.829 7.029 5.829 2.246 0 4.057-.972 5.428-2.914 1.373-1.942 2.059-4.534 2.059-7.771 0-3.391-.629-5.971-1.885-7.743-1.258-1.771-3.066-2.657-5.43-2.657-4.268 0-6.667 1.885-7.2 5.656h2.343l-6.342 6.343-6.343-6.343 2.512.001z"
  />
</svg>
</div>
        </div>

  </div>
    <div>
      <a
        href="https://github.com/michenriksen/hugo-theme-til"
        title="Today I Learned &#8212; A Hugo theme by Michael Henriksen"
        data-theme-version="0.4.0"
        >theme: til</a
      >
    </div>
</section>

      </footer>
    </div>
    
  </body>
</html>
