<!doctype html>
<html
  lang="en-us"
  dir="ltr"
>
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    
<link rel="stylesheet" href="http://localhost:1313/css/styles.min.29149e7eece4eab92c5f2dc32ab7ccaad6427a19dd21db0153b88b4ccb8f3645.css">
<meta charset="utf-8" />
<meta name="language" content="en" />
<meta name="viewport" content="width=device-width" />
<title>
    Is Generative Recommendation the Future of RecSys? | Yuan Meng
</title>
  <meta name="description" content="For nearly a decade, recommender systems have remained largely the same. System-wise, most companies adopt the cascade pipeline in the iconic YouTube paper, retrieving tens of thousands of candidates from a massive corpus, trimming them down to thousands of roughly relevant items with a lightweight ranker (L1), before selecting the top dozen using a heavy ranker (L2) and making adjustments based on policy and business logic (L3). Architecture-wise, the L2 ranker hasn‚Äôt drifted far from the Deep &amp; Wide network. Years of incremental improvements on feature interaction (e.g., DCN-v2, MaskNet) and multi-task learning (e.g., MMoE, PLE) culminated in Meta‚Äôs DHEN that combines multiple interaction modules and experts to push the limits of this ‚ÄúDeep Learning Recommender System‚Äù (DLRM) paradigm.
Since 2016, web-scale recommender systems mostly use the cascade pipeline and DLRM-style ‚ÄòEmbedding &amp; Interaction &amp; Expert‚Äô model architectures.
In 2025, the tide seems to have finally turned after Meta‚Äôs HSTU delivered the biggest model performance and business metric gains that the company has seen in years ‚Äî other top companies such as Google, Netflix, Kuaishou, Xiaohongshu, Alibaba, Tencent, Baidu, and Meituan are starting to embrace a new ‚ÄúGenerative Recommendation‚Äù (GM) paradigm, reframing the discriminative pAction prediction task to a generative task, akin to token prediction in language modeling." />
<meta property="og:url" content="http://localhost:1313/posts/generative_recommendation/">
  <meta property="og:site_name" content="Yuan Meng">
  <meta property="og:title" content="Is Generative Recommendation the Future of RecSys?">
  <meta property="og:description" content="For nearly a decade, recommender systems have remained largely the same. System-wise, most companies adopt the cascade pipeline in the iconic YouTube paper, retrieving tens of thousands of candidates from a massive corpus, trimming them down to thousands of roughly relevant items with a lightweight ranker (L1), before selecting the top dozen using a heavy ranker (L2) and making adjustments based on policy and business logic (L3). Architecture-wise, the L2 ranker hasn‚Äôt drifted far from the Deep &amp; Wide network. Years of incremental improvements on feature interaction (e.g., DCN-v2, MaskNet) and multi-task learning (e.g., MMoE, PLE) culminated in Meta‚Äôs DHEN that combines multiple interaction modules and experts to push the limits of this ‚ÄúDeep Learning Recommender System‚Äù (DLRM) paradigm.
Since 2016, web-scale recommender systems mostly use the cascade pipeline and DLRM-style ‚ÄòEmbedding &amp; Interaction &amp; Expert‚Äô model architectures.
In 2025, the tide seems to have finally turned after Meta‚Äôs HSTU delivered the biggest model performance and business metric gains that the company has seen in years ‚Äî other top companies such as Google, Netflix, Kuaishou, Xiaohongshu, Alibaba, Tencent, Baidu, and Meituan are starting to embrace a new ‚ÄúGenerative Recommendation‚Äù (GM) paradigm, reframing the discriminative pAction prediction task to a generative task, akin to token prediction in language modeling.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-07-20T00:00:00+00:00">


  <meta itemprop="name" content="Is Generative Recommendation the Future of RecSys?">
  <meta itemprop="description" content="For nearly a decade, recommender systems have remained largely the same. System-wise, most companies adopt the cascade pipeline in the iconic YouTube paper, retrieving tens of thousands of candidates from a massive corpus, trimming them down to thousands of roughly relevant items with a lightweight ranker (L1), before selecting the top dozen using a heavy ranker (L2) and making adjustments based on policy and business logic (L3). Architecture-wise, the L2 ranker hasn‚Äôt drifted far from the Deep &amp; Wide network. Years of incremental improvements on feature interaction (e.g., DCN-v2, MaskNet) and multi-task learning (e.g., MMoE, PLE) culminated in Meta‚Äôs DHEN that combines multiple interaction modules and experts to push the limits of this ‚ÄúDeep Learning Recommender System‚Äù (DLRM) paradigm.
Since 2016, web-scale recommender systems mostly use the cascade pipeline and DLRM-style ‚ÄòEmbedding &amp; Interaction &amp; Expert‚Äô model architectures.
In 2025, the tide seems to have finally turned after Meta‚Äôs HSTU delivered the biggest model performance and business metric gains that the company has seen in years ‚Äî other top companies such as Google, Netflix, Kuaishou, Xiaohongshu, Alibaba, Tencent, Baidu, and Meituan are starting to embrace a new ‚ÄúGenerative Recommendation‚Äù (GM) paradigm, reframing the discriminative pAction prediction task to a generative task, akin to token prediction in language modeling.">
  <meta itemprop="datePublished" content="2025-07-20T00:00:00+00:00">
  <meta itemprop="wordCount" content="571">
  <meta itemprop="keywords" content="Generative recommendation,Large language models">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Is Generative Recommendation the Future of RecSys?">
  <meta name="twitter:description" content="For nearly a decade, recommender systems have remained largely the same. System-wise, most companies adopt the cascade pipeline in the iconic YouTube paper, retrieving tens of thousands of candidates from a massive corpus, trimming them down to thousands of roughly relevant items with a lightweight ranker (L1), before selecting the top dozen using a heavy ranker (L2) and making adjustments based on policy and business logic (L3). Architecture-wise, the L2 ranker hasn‚Äôt drifted far from the Deep &amp; Wide network. Years of incremental improvements on feature interaction (e.g., DCN-v2, MaskNet) and multi-task learning (e.g., MMoE, PLE) culminated in Meta‚Äôs DHEN that combines multiple interaction modules and experts to push the limits of this ‚ÄúDeep Learning Recommender System‚Äù (DLRM) paradigm.
Since 2016, web-scale recommender systems mostly use the cascade pipeline and DLRM-style ‚ÄòEmbedding &amp; Interaction &amp; Expert‚Äô model architectures.
In 2025, the tide seems to have finally turned after Meta‚Äôs HSTU delivered the biggest model performance and business metric gains that the company has seen in years ‚Äî other top companies such as Google, Netflix, Kuaishou, Xiaohongshu, Alibaba, Tencent, Baidu, and Meituan are starting to embrace a new ‚ÄúGenerative Recommendation‚Äù (GM) paradigm, reframing the discriminative pAction prediction task to a generative task, akin to token prediction in language modeling.">

<link rel="canonical" href="http://localhost:1313/posts/generative_recommendation/" />

    <link rel="stylesheet" href="/css/index.css" />


      <script src="/js/main.js" defer></script>
  

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org/",
  "@id": "http://localhost:1313/posts/generative_recommendation/",
  "@type": "BlogPosting",
  "articleSection": [
    "Generative recommendation",
    "Large language models"
  ],
  "author": {
    "@type": "Person",
    "email": "mycaptainmy@gmail.com",
    "name": "Yuan Meng",
    "url": "http://localhost:1313/about/"
  },
  "copyrightNotice": "Yuan Meng",
  "datePublished": "2025-07-20",
  "description": "For nearly a decade, recommender systems have remained largely the same. System-wise, most companies adopt the cascade pipeline in the iconic YouTube paper, retrieving tens of thousands of candidates from a massive corpus, trimming them down to thousands of roughly relevant items with a lightweight ranker (L1), before selecting the top dozen using a heavy ranker (L2) and making adjustments based on policy and business logic (L3). Architecture-wise, the L2 ranker hasn‚Äôt drifted far from the Deep \u0026 Wide network. Years of incremental improvements on feature interaction (e.g., DCN-v2, MaskNet) and multi-task learning (e.g., MMoE, PLE) culminated in Meta‚Äôs DHEN that combines multiple interaction modules and experts to push the limits of this ‚ÄúDeep Learning Recommender System‚Äù (DLRM) paradigm.\nSince 2016, web-scale recommender systems mostly use the cascade pipeline and DLRM-style ‚ÄòEmbedding \u0026 Interaction \u0026 Expert‚Äô model architectures.\nIn 2025, the tide seems to have finally turned after Meta‚Äôs HSTU delivered the biggest model performance and business metric gains that the company has seen in years ‚Äî other top companies such as Google, Netflix, Kuaishou, Xiaohongshu, Alibaba, Tencent, Baidu, and Meituan are starting to embrace a new ‚ÄúGenerative Recommendation‚Äù (GM) paradigm, reframing the discriminative pAction prediction task to a generative task, akin to token prediction in language modeling.",
  "headline": "Is Generative Recommendation the Future of RecSys?",
  "isPartOf": {
    "@id": "http://localhost:1313/posts/",
    "@type": "Blog",
    "name": "Posts"
  },
  "mainEntityOfPage": "http://localhost:1313/posts/generative_recommendation/",
  "name": "Is Generative Recommendation the Future of RecSys?",
  "timeRequired": "PT3M",
  "url": "http://localhost:1313/posts/generative_recommendation/",
  "wordCount": 571
}
</script>


  </head>
  <body>
    <div class="container mx-auto flex max-w-prose flex-col space-y-10 p-4 md:p-6">
      <header class="flex flex-row items-center justify-between">
        <div>
  <a id="skip-nav" class="sr-only" href="#maincontent">Skip to main content</a>
  <a class="font-semibold" href="/">Yuan Meng</a>
</div>

  <nav>
    <ul class="flex flex-row items-center justify-end space-x-4">
    <li>
      <a href="/about/">About</a
      >
    </li>
    <li>
      <a aria-current="true" class="ancestor" href="/posts/">Posts</a
      >
    </li>
    <li>
      <a href="/notes/">Notes</a
      >
    </li>
    </ul>
  </nav>


      </header>
      <main class="prose prose-slate relative md:prose-lg prose-h1:text-[2em]" id="maincontent">
        <article class="main">
    <header>
      <h1 class="!mb-1">Is Generative Recommendation the Future of RecSys?</h1><div class="flex flex-row items-center space-x-4">
          <time class="text-sm italic opacity-80" datetime="2025-07-20T00:00:00&#43;00:00">July 20, 2025</time>
        </div>
    </header>

    
    
      Reading time: 3 minutes
    

    
    
      <div class="toc-container">
        <span id="toc-toggle">
          <span id="toc-icon">‚ñ∂</span> 
          <span>Table of Contents</span>
        </span>
        <nav id="TableOfContents" class="toc-content">
          <nav id="TableOfContents">
  <ul>
    <li><a href="#references">References</a>
      <ul>
        <li><a href="#precursors-to-generative-recommendation">Precursors to Generative Recommendation</a></li>
        <li><a href="#generative-recommendation-for-retrieval">Generative Recommendation for Retrieval</a></li>
        <li><a href="#generative-recommendation-for-ranking">Generative Recommendation for Ranking</a></li>
      </ul>
    </li>
  </ul>
</nav>
        </nav>
      </div>

      <script>
        
        document.addEventListener('DOMContentLoaded', function () {
          var tocToggle = document.getElementById('toc-toggle');
          var tocContent = document.getElementById('TableOfContents');
          var tocIcon = document.getElementById('toc-icon');
          tocToggle.addEventListener('click', function () {
            if (tocContent.style.display === 'none' || tocContent.style.display === '') {
              tocContent.style.display = 'block';
              tocIcon.textContent = '‚ñº'; 
            } else {
              tocContent.style.display = 'none';
              tocIcon.textContent = '‚ñ∂'; 
            }
          });
        });
      </script>
    

    
    <div class="content">
      <p>For nearly a decade, recommender systems have remained largely the same. System-wise, most companies adopt the cascade pipeline in the iconic <a href="https://research.google.com/pubs/archive/45530.pdf">YouTube paper</a>, retrieving tens of thousands of candidates from a massive corpus, trimming them down to thousands of roughly relevant items with a lightweight ranker (L1), before selecting the top dozen using a heavy ranker (L2) and making adjustments based on policy and business logic (L3). Architecture-wise, the L2 ranker hasn&rsquo;t drifted far from the <a href="https://arxiv.org/abs/1606.07792">Deep &amp; Wide network</a>. Years of incremental improvements on feature interaction (e.g., <a href="https://arxiv.org/abs/2008.13535">DCN-v2</a>, <a href="https://arxiv.org/abs/2102.07619">MaskNet</a>) and multi-task learning (e.g., <a href="https://arxiv.org/abs/2311.09580">MMoE</a>, <a href="https://dl.acm.org/doi/abs/10.1145/3383313.3412236">PLE</a>) culminated in Meta&rsquo;s <a href="https://arxiv.org/abs/2203.11014">DHEN</a> that combines multiple interaction modules and experts to push the limits of this &ldquo;Deep Learning Recommender System&rdquo; (DLRM) paradigm.</p>
<figure><img src="https://www.dropbox.com/scl/fi/96m8zb5yps9ffz9geheu7/Screenshot-2025-07-20-at-11.07.10-PM.png?rlkey=q4xtbxt3r50okrs2zo9vac2xq&amp;st=fzobjxgt&amp;raw=1"
    alt="Since 2016, web-scale recommender systems mostly use the cascade pipeline and DLRM-style &lsquo;Embedding &amp; Interaction &amp; Expert&rsquo; model architectures." width="1800"><figcaption>
      <p>Since 2016, web-scale recommender systems mostly use the cascade pipeline and DLRM-style &lsquo;Embedding &amp; Interaction &amp; Expert&rsquo; model architectures.</p>
    </figcaption>
</figure>

<p>In 2025, the tide seems to have finally turned after Meta&rsquo;s <a href="https://arxiv.org/abs/2402.17152">HSTU</a> delivered the biggest model performance and business metric gains that the company has seen in years &mdash; other top companies such as Google, Netflix, Kuaishou, Xiaohongshu, Alibaba, Tencent, Baidu, and Meituan are starting to embrace a new &ldquo;Generative Recommendation&rdquo; (GM) paradigm, reframing the discriminative pAction prediction task to a generative task, akin to token prediction in language modeling.</p>
<p>What makes Generative Recommendation so magical? Why is it able to unlock the scaling law in recommender systems in ways that DLRM wasn&rsquo;t able to? Is GM a genuine paradigm shift or a short-lived fad? In this blogpost, let&rsquo;s take a look at GM models coming out from the aforementioned companies and see what the fuss is all about üïµÔ∏è.</p>
<h2 id="references" class="scroll-mt-8 group">
  References
  
    <a href="#references"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h2>
<h3 id="precursors-to-generative-recommendation" class="scroll-mt-8 group">
  Precursors to Generative Recommendation
  
    <a href="#precursors-to-generative-recommendation"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<ol>
<li>RQ-VAE, the technique behind Semantic ID learning üëâ <a href="https://arxiv.org/abs/2203.01941"><em>Autoregressive Image Generation using Residual Quantization</em></a> (2022) by Lee et al., <em>CVPR</em>.</li>
<li>Google DeepMind first introduced Semantic IDs üëâ <a href="https://dl.acm.org/doi/abs/10.1145/3640457.3688190"><em>Better Generalization with Semantic IDs: A Case Study in Ranking for Recommendations</em></a> (2024) by Singh et al., <em>RecSys</em>.</li>
<li>COBRA addresses information loss from quantization üëâ <a href="https://arxiv.org/abs/2503.02453"><em>Sparse Meets Dense: Unified Generative Recommendations with Cascaded Sparse-Dense Representations</em></a> (2025) by Yang et al., <em>arXiv</em>.</li>
</ol>
<h3 id="generative-recommendation-for-retrieval" class="scroll-mt-8 group">
  Generative Recommendation for Retrieval
  
    <a href="#generative-recommendation-for-retrieval"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<ol start="4">
<li>Google DeepMind&rsquo;s TIGER üëâ <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/20dcab0f14046a5c6b02b61da9f13229-Abstract-Conference.html"><em>Recommender Systems with Generative Retrieval</em></a> (2023) by Rajput et al., <em>NeurIPS</em>.</li>
<li>Alibaba&rsquo;s URM üëâ <a href="https://arxiv.org/abs/2502.03041"><em>Large Language Model as Universal Retriever in Industrial-Scale Recommender System</em></a> (2025) by Jiang et al., <em>arXiv</em>.</li>
<li>Baidu&rsquo;s GBS üëâ <a href="https://arxiv.org/abs/2501.11034"><em>Generative Retrieval for Book Search</em></a> (2025) by Tang et al., <em>KDD</em>.</li>
<li>Scaling law analysis üëâ <a href="https://dl.acm.org/doi/abs/10.1145/3726302.3729973"><em>Exploring Training and Inference Scaling Laws in Generative Retrieval</em></a> (2025) by Cai et al., <em>SIGIR</em>.</li>
</ol>
<h3 id="generative-recommendation-for-ranking" class="scroll-mt-8 group">
  Generative Recommendation for Ranking
  
    <a href="#generative-recommendation-for-ranking"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<ol start="8">
<li>Meta&rsquo;s HSTU üëâ <a href="https://arxiv.org/abs/2402.17152"><em>Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations</em></a> (2024) by Zhai et al., <em>ICML</em>.
<ul>
<li>Related analysis: <a href="https://arxiv.org/abs/2208.08489"><em>Understanding Scaling Laws for Recommendation Models</em></a> by the same team at Meta.</li>
</ul>
</li>
<li>Netflix üëâ <a href="https://netflixtechblog.com/foundation-model-for-personalized-recommendation-1a0bd8e02d39"><em>Foundation Model for Personalized Recommendation</em></a> (2025) by  Hsiao et al., <em>Netflix Technology Blog</em>.</li>
<li>Xiaohongshu&rsquo;s RankGPT üëâ <a href="https://arxiv.org/abs/2505.04180"><em>Towards Large-Scale Generative Ranking</em></a> (2025) by Huang et al., <em>arXiv</em>.</li>
<li>Kuaishou&rsquo;s OneRec üëâ <a href="https://arxiv.org/abs/2502.18965"><em>OneRec: Unifying Retrieve and Rank with Generative Recommender and Iterative Preference Alignment</em></a> (2025) by Deng et al., <em>arXiv</em>.</li>
<li>Meituan&rsquo;s MTGR üëâ <a href="https://arxiv.org/abs/2505.18654"><em>MTGR: Industrial-Scale Generative Recommendation Framework in Meituan</em></a> (2025) by Han et al., <em>arXiv</em>.</li>
<li>Alibaba&rsquo;s LUM üëâ <a href="https://arxiv.org/abs/2502.08309"><em>Unlocking Scaling Law in Industrial Recommendation Systems with a Three-step Paradigm based Large User Model</em></a> (2025) by Yan et al., <em>arXiv</em>.</li>
<li>Alibaba&rsquo;s GPSD üëâ <a href="https://arxiv.org/abs/2506.03699"><em>Scaling Transformers for Discriminative Recommendation via Generative Pretraining</em></a> (2025) by Wang et al., <em>KDD</em>.</li>
<li>Tencent üëâ <a href="https://dl.acm.org/doi/abs/10.1145/3640457.3688129"><em>Scaling Law of Large Sequential Recommendation Models</em></a> (2025) by Zhang et al., <em>RecSys</em>.</li>
</ol>
    </div>
  </article>

  
    <aside class="not-prose flex flex-col space-y-8 border-t pt-6">
    <section class="flex flex-col space-y-4">
      <h2 class="flex flex-row items-center space-x-2 text-lg font-semibold">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-shapes h-4 w-4"
  viewBox="0 0 24 24"
  aria-hidden="true"
>
  <path
    d="M8.3 10a.7.7 0 0 1-.626-1.079L11.4 3a.7.7 0 0 1 1.198-.043L16.3 8.9a.7.7 0 0 1-.572 1.1Z"
  />
  <rect width="7" height="7" x="3" y="14" rx="1" />
  <circle cx="17.5" cy="17.5" r="3.5" />
</svg>

        <span>Categories</span>
      </h2>

      <ul class="ml-6 flex flex-row flex-wrap items-center space-x-2">
          <li>
            <a href="/categories/generative-recommendation/" class="taxonomy category">generative recommendation</a>
          </li>
          <li>
            <a href="/categories/large-language-models/" class="taxonomy category">large language models</a>
          </li>
      </ul>
    </section>
    <section class="flex flex-col space-y-4" aria-hidden="true">
      <h2 class="flex flex-row items-center space-x-2 text-lg font-semibold">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-chart-network h-4 w-4"
  viewBox="0 0 24 24"
  aria-hidden="true"
>
  <path
    d="m13.11 7.664 1.78 2.672M14.162 12.788l-3.324 1.424M20 4l-6.06 1.515M3 3v16a2 2 0 0 0 2 2h16"
  />
  <circle cx="12" cy="6" r="2" />
  <circle cx="16" cy="12" r="2" />
  <circle cx="9" cy="15" r="2" />
</svg>

        <span>Graph</span>
      </h2>

      <content-network-graph
  class="h-64 ml-6"
  data-endpoint="/graph/index.json"
  page="/posts/generative_recommendation/"
></content-network-graph>

    </section>
</aside>

      </main>
      <footer class="mt-20 border-t border-neutral-100 pt-2 text-xs">
        
<section class="items-top flex flex-row justify-between opacity-70">
  <div class="flex flex-col space-y-2">
      <p>Copyright &copy; 2025, Yuan Meng.</p>
      <div
        xmlns:cc="https://creativecommons.org/ns#"
        xmlns:dct="http://purl.org/dc/terms/"
        about="https://creativecommons.org"
      >
        Content is available under
        <a href="https://creativecommons.org/licenses/by-sa/4.0/" rel="license" class="inline-block" title="Creative Commons Attribution-ShareAlike 4.0 International"
          >CC BY-SA 4.0</a
        >
        unless otherwise noted.
      </div>
        <div
          class="mt-2 flex items-center space-x-2 fill-slate-400 hover:fill-slate-600 motion-safe:transition-colors"
        >
          <div class="flex-none cursor-help"><svg
  version="1.0"
  xmlns="http://www.w3.org/2000/svg"
  viewBox="5.5 -3.5 64 64"
  xml:space="preserve"
  class="w-5 h-5 block"
  aria-hidden="true"
>
  <title>Creative Commons</title>
  <circle fill="transparent" cx="37.785" cy="28.501" r="28.836" />
  <path
    d="M37.441-3.5c8.951 0 16.572 3.125 22.857 9.372 3.008 3.009 5.295 6.448 6.857 10.314 1.561 3.867 2.344 7.971 2.344 12.314 0 4.381-.773 8.486-2.314 12.313-1.543 3.828-3.82 7.21-6.828 10.143-3.123 3.085-6.666 5.448-10.629 7.086-3.961 1.638-8.057 2.457-12.285 2.457s-8.276-.808-12.143-2.429c-3.866-1.618-7.333-3.961-10.4-7.027-3.067-3.066-5.4-6.524-7-10.372S5.5 32.767 5.5 28.5c0-4.229.809-8.295 2.428-12.2 1.619-3.905 3.972-7.4 7.057-10.486C21.08-.394 28.565-3.5 37.441-3.5zm.116 5.772c-7.314 0-13.467 2.553-18.458 7.657-2.515 2.553-4.448 5.419-5.8 8.6a25.204 25.204 0 0 0-2.029 9.972c0 3.429.675 6.734 2.029 9.913 1.353 3.183 3.285 6.021 5.8 8.516 2.514 2.496 5.351 4.399 8.515 5.715a25.652 25.652 0 0 0 9.943 1.971c3.428 0 6.75-.665 9.973-1.999 3.219-1.335 6.121-3.257 8.713-5.771 4.99-4.876 7.484-10.99 7.484-18.344 0-3.543-.648-6.895-1.943-10.057-1.293-3.162-3.18-5.98-5.654-8.458-5.146-5.143-11.335-7.715-18.573-7.715zm-.401 20.915-4.287 2.229c-.458-.951-1.019-1.619-1.685-2-.667-.38-1.286-.571-1.858-.571-2.856 0-4.286 1.885-4.286 5.657 0 1.714.362 3.084 1.085 4.113.724 1.029 1.791 1.544 3.201 1.544 1.867 0 3.181-.915 3.944-2.743l3.942 2c-.838 1.563-2 2.791-3.486 3.686-1.484.896-3.123 1.343-4.914 1.343-2.857 0-5.163-.875-6.915-2.629-1.752-1.752-2.628-4.19-2.628-7.313 0-3.048.886-5.466 2.657-7.257 1.771-1.79 4.009-2.686 6.715-2.686 3.963-.002 6.8 1.541 8.515 4.627zm18.457 0-4.229 2.229c-.457-.951-1.02-1.619-1.686-2-.668-.38-1.307-.571-1.914-.571-2.857 0-4.287 1.885-4.287 5.657 0 1.714.363 3.084 1.086 4.113.723 1.029 1.789 1.544 3.201 1.544 1.865 0 3.18-.915 3.941-2.743l4 2c-.875 1.563-2.057 2.791-3.541 3.686a9.233 9.233 0 0 1-4.857 1.343c-2.896 0-5.209-.875-6.941-2.629-1.736-1.752-2.602-4.19-2.602-7.313 0-3.048.885-5.466 2.658-7.257 1.77-1.79 4.008-2.686 6.713-2.686 3.962-.002 6.783 1.541 8.458 4.627z"
  />
</svg>
</div><div class="flex-none cursor-help"><svg
  version="1.0"
  xmlns="http://www.w3.org/2000/svg"
  viewBox="5.5 -3.5 64 64"
  xml:space="preserve"
  class="w-5 h-5 block"
>
  <title>Credit must be given to the creator</title>
  <circle fill="transparent" cx="37.637" cy="28.806" r="28.276" />
  <path
    d="M37.443-3.5c8.988 0 16.57 3.085 22.742 9.257C66.393 11.967 69.5 19.548 69.5 28.5c0 8.991-3.049 16.476-9.145 22.456-6.476 6.363-14.113 9.544-22.912 9.544-8.649 0-16.153-3.144-22.514-9.43C8.644 44.784 5.5 37.262 5.5 28.5c0-8.761 3.144-16.342 9.429-22.742C21.101-.415 28.604-3.5 37.443-3.5zm.114 5.772c-7.276 0-13.428 2.553-18.457 7.657-5.22 5.334-7.829 11.525-7.829 18.572 0 7.086 2.59 13.22 7.77 18.398 5.181 5.182 11.352 7.771 18.514 7.771 7.123 0 13.334-2.607 18.629-7.828 5.029-4.838 7.543-10.952 7.543-18.343 0-7.276-2.553-13.465-7.656-18.571-5.104-5.104-11.276-7.656-18.514-7.656zm8.572 18.285v13.085h-3.656v15.542h-9.944V33.643h-3.656V20.557c0-.572.2-1.057.599-1.457.401-.399.887-.6 1.457-.6h13.144c.533 0 1.01.2 1.428.6.417.4.628.886.628 1.457zm-13.087-8.228c0-3.008 1.485-4.514 4.458-4.514s4.457 1.504 4.457 4.514c0 2.971-1.486 4.457-4.457 4.457s-4.458-1.486-4.458-4.457z"
  />
</svg>
</div><div class="flex-none cursor-help"><svg
  version="1.0"
  xmlns="http://www.w3.org/2000/svg"
  viewBox="5.5 -3.5 64 64"
  xml:space="preserve"
  class="w-5 h-5 block"
>
  <title>Adaptations must be shared under the same terms</title>
  <circle fill="transparent" cx="36.944" cy="28.631" r="29.105" />
  <path
    d="M37.443-3.5c8.951 0 16.531 3.105 22.742 9.315C66.393 11.987 69.5 19.548 69.5 28.5c0 8.954-3.049 16.457-9.145 22.514-6.437 6.324-14.076 9.486-22.912 9.486-8.649 0-16.153-3.143-22.514-9.429C8.644 44.786 5.5 37.264 5.5 28.501c0-8.723 3.144-16.285 9.429-22.685C21.138-.395 28.643-3.5 37.443-3.5zm.114 5.772c-7.276 0-13.428 2.572-18.457 7.715-5.22 5.296-7.829 11.467-7.829 18.513 0 7.125 2.59 13.257 7.77 18.4 5.181 5.182 11.352 7.771 18.514 7.771 7.123 0 13.334-2.609 18.629-7.828 5.029-4.876 7.543-10.99 7.543-18.343 0-7.313-2.553-13.485-7.656-18.513-5.067-5.145-11.239-7.715-18.514-7.715zM23.271 23.985c.609-3.924 2.189-6.962 4.742-9.114 2.552-2.152 5.656-3.228 9.314-3.228 5.027 0 9.029 1.62 12 4.856 2.971 3.238 4.457 7.391 4.457 12.457 0 4.915-1.543 9-4.627 12.256-3.088 3.256-7.086 4.886-12.002 4.886-3.619 0-6.743-1.085-9.371-3.257-2.629-2.172-4.209-5.257-4.743-9.257H31.1c.19 3.886 2.533 5.829 7.029 5.829 2.246 0 4.057-.972 5.428-2.914 1.373-1.942 2.059-4.534 2.059-7.771 0-3.391-.629-5.971-1.885-7.743-1.258-1.771-3.066-2.657-5.43-2.657-4.268 0-6.667 1.885-7.2 5.656h2.343l-6.342 6.343-6.343-6.343 2.512.001z"
  />
</svg>
</div>
        </div>

  </div>
    <div>
      <a
        href="https://github.com/michenriksen/hugo-theme-til"
        title="Today I Learned &#8212; A Hugo theme by Michael Henriksen"
        data-theme-version="0.4.0"
        >theme: til</a
      >
    </div>
</section>

      </footer>
    </div>

    
    <button id="back-to-top" title="Go to top">‚òùÔ∏è</button>


    
    

    
    <script src="/js/back-to-top.js"></script>

     
    <script src="/js/cat-cursor.js" defer></script>
  </body>
</html>
