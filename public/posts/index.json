[{"categories":["Recommender systems"],"date":"2024-11-10T00:00:00Z","id":"/posts/seq_user_modeling/","keywords":[],"summary":"\u003ch2 id=\"references\" class=\"scroll-mt-8 group\"\u003e\n  References\n  \n    \u003ca href=\"#references\"\n        class=\"no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block\"\n        aria-hidden=\"true\" title=\"Link to this heading\" tabindex=\"-1\"\u003e\n        \u003csvg\n  xmlns=\"http://www.w3.org/2000/svg\"\n  width=\"16\"\n  height=\"16\"\n  fill=\"none\"\n  stroke=\"currentColor\"\n  stroke-linecap=\"round\"\n  stroke-linejoin=\"round\"\n  stroke-width=\"2\"\n  class=\"lucide lucide-link w-4 h-4 block\"\n  viewBox=\"0 0 24 24\"\n\u003e\n  \u003cpath d=\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\" /\u003e\n  \u003cpath d=\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\" /\u003e\n\u003c/svg\u003e\n\n    \u003c/a\u003e\n  \n\u003c/h2\u003e\n\u003ch3 id=\"papers\" class=\"scroll-mt-8 group\"\u003e\n  Papers\n  \n    \u003ca href=\"#papers\"\n        class=\"no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block\"\n        aria-hidden=\"true\" title=\"Link to this heading\" tabindex=\"-1\"\u003e\n        \u003csvg\n  xmlns=\"http://www.w3.org/2000/svg\"\n  width=\"16\"\n  height=\"16\"\n  fill=\"none\"\n  stroke=\"currentColor\"\n  stroke-linecap=\"round\"\n  stroke-linejoin=\"round\"\n  stroke-width=\"2\"\n  class=\"lucide lucide-link w-4 h-4 block\"\n  viewBox=\"0 0 24 24\"\n\u003e\n  \u003cpath d=\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\" /\u003e\n  \u003cpath d=\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\" /\u003e\n\u003c/svg\u003e\n\n    \u003c/a\u003e\n  \n\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"https://openreview.net/forum?id=Gny0PVtKz2\"\u003e\u003cem\u003eConvFormer: Revisiting Token-mixers for Sequential User Modeling\u003c/em\u003e\u003c/a\u003e (2024) by Wang et al., \u003cem\u003eICLR\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://arxiv.org/abs/2205.04507\"\u003e\u003cem\u003ePinnerFormer: Sequence Modeling for User Representation at Pinterest\u003c/em\u003e\u003c/a\u003e (2022) by Pancha et al., \u003cem\u003eKDD\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://arxiv.org/abs/2306.00248\"\u003e\u003cem\u003eTransAct: Transformer-based Realtime User Action Model for Recommendation at Pinterest\u003c/em\u003e\u003c/a\u003e (2024) by Xia et al., \u003cem\u003eKDD\u003c/em\u003e.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"blogposts\" class=\"scroll-mt-8 group\"\u003e\n  Blogposts\n  \n    \u003ca href=\"#blogposts\"\n        class=\"no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block\"\n        aria-hidden=\"true\" title=\"Link to this heading\" tabindex=\"-1\"\u003e\n        \u003csvg\n  xmlns=\"http://www.w3.org/2000/svg\"\n  width=\"16\"\n  height=\"16\"\n  fill=\"none\"\n  stroke=\"currentColor\"\n  stroke-linecap=\"round\"\n  stroke-linejoin=\"round\"\n  stroke-width=\"2\"\n  class=\"lucide lucide-link w-4 h-4 block\"\n  viewBox=\"0 0 24 24\"\n\u003e\n  \u003cpath d=\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\" /\u003e\n  \u003cpath d=\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\" /\u003e\n\u003c/svg\u003e\n\n    \u003c/a\u003e\n  \n\u003c/h3\u003e\n\u003col start=\"4\"\u003e\n\u003cli\u003e\u003ca href=\"https://research.google/blog/transformers-in-music-recommendation/\"\u003e\u003cem\u003eTransformers in music recommendation\u003c/em\u003e\u003c/a\u003e by Google Research.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/pinterest-engineering/large-scale-user-sequences-at-pinterest-78a5075a3fe9\"\u003e\u003cem\u003eLarge-scale User Sequences at Pinterest\u003c/em\u003e\u003c/a\u003e by Pinterest Engineering.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/pinterest-engineering/user-action-sequence-modeling-for-pinterest-ads-engagement-modeling-21139cab8f4e\"\u003e\u003cem\u003eUser Action Sequence Modeling for Pinterest Ads Engagement Modeling\u003c/em\u003e\u003c/a\u003e by Pinterest Engineering.\u003c/li\u003e\n\u003c/ol\u003e","tags":[],"title":"Down the Rabbit Hole: Sequential User Modeling"},{"categories":["Career","Machine learning","Interview"],"date":"2024-10-15T00:00:00Z","id":"/posts/mle_interviews/","keywords":[],"summary":"\u003ch2 id=\"the-marriage-analogy\" class=\"scroll-mt-8 group\"\u003e\n  The Marriage Analogy\n  \n    \u003ca href=\"#the-marriage-analogy\"\n        class=\"no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block\"\n        aria-hidden=\"true\" title=\"Link to this heading\" tabindex=\"-1\"\u003e\n        \u003csvg\n  xmlns=\"http://www.w3.org/2000/svg\"\n  width=\"16\"\n  height=\"16\"\n  fill=\"none\"\n  stroke=\"currentColor\"\n  stroke-linecap=\"round\"\n  stroke-linejoin=\"round\"\n  stroke-width=\"2\"\n  class=\"lucide lucide-link w-4 h-4 block\"\n  viewBox=\"0 0 24 24\"\n\u003e\n  \u003cpath d=\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\" /\u003e\n  \u003cpath d=\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\" /\u003e\n\u003c/svg\u003e\n\n    \u003c/a\u003e\n  \n\u003c/h2\u003e\n\u003cp\u003eOver 2 years ago, I wrote a \u003ca href=\"https://www.yuan-meng.com/posts/newgrads/\"\u003eblog post\u003c/a\u003e on how to find jobs as a new grad data scientist (as a twist of fate, I never worked as a product data scientist but instead became an ML engineer at DoorDash). Back in 2021, I cared a ton about interview skills, answer \u0026ldquo;frameworks\u0026rdquo;, and whatnot, which may still come handy at New Grad or Early Career levels. For experienced hires, however, I think of interviews as some sort of marriage proposal \u0026mdash; \u003cem\u003eit\u0026rsquo;s something you can rehearse but can never force\u003c/em\u003e.\u003c/p\u003e","tags":[],"title":"(Opinionated) Guide to ML Engineer Job Hunting"},{"categories":["AI","Cognitive science"],"date":"2024-10-13T00:00:00Z","id":"/posts/human_vision/","keywords":[],"summary":"\u003ch2 id=\"engineer-the-mind\" class=\"scroll-mt-8 group\"\u003e\n  Engineer the Mind\n  \n    \u003ca href=\"#engineer-the-mind\"\n        class=\"no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block\"\n        aria-hidden=\"true\" title=\"Link to this heading\" tabindex=\"-1\"\u003e\n        \u003csvg\n  xmlns=\"http://www.w3.org/2000/svg\"\n  width=\"16\"\n  height=\"16\"\n  fill=\"none\"\n  stroke=\"currentColor\"\n  stroke-linecap=\"round\"\n  stroke-linejoin=\"round\"\n  stroke-width=\"2\"\n  class=\"lucide lucide-link w-4 h-4 block\"\n  viewBox=\"0 0 24 24\"\n\u003e\n  \u003cpath d=\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\" /\u003e\n  \u003cpath d=\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\" /\u003e\n\u003c/svg\u003e\n\n    \u003c/a\u003e\n  \n\u003c/h2\u003e\n\u003cp\u003eIn Winter 2015, after coming back from grad school interviews in the States, I told my dad over hotpot that I was going to study \u003ca href=\"https://en.wikipedia.org/wiki/Cognitive_science\"\u003ecognitive science\u003c/a\u003e at Berkeley.\u003c/p\u003e","tags":[],"title":"Is Human Vision More like CNN or Vision Transformer?"},{"categories":["Negative sampling","Recommender system"],"date":"2024-09-02T00:00:00Z","id":"/posts/negative_sampling/","keywords":[],"summary":"\u003ch2 id=\"web-scale-recommender-systems\" class=\"scroll-mt-8 group\"\u003e\n  Web-Scale Recommender Systems\n  \n    \u003ca href=\"#web-scale-recommender-systems\"\n        class=\"no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block\"\n        aria-hidden=\"true\" title=\"Link to this heading\" tabindex=\"-1\"\u003e\n        \u003csvg\n  xmlns=\"http://www.w3.org/2000/svg\"\n  width=\"16\"\n  height=\"16\"\n  fill=\"none\"\n  stroke=\"currentColor\"\n  stroke-linecap=\"round\"\n  stroke-linejoin=\"round\"\n  stroke-width=\"2\"\n  class=\"lucide lucide-link w-4 h-4 block\"\n  viewBox=\"0 0 24 24\"\n\u003e\n  \u003cpath d=\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\" /\u003e\n  \u003cpath d=\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\" /\u003e\n\u003c/svg\u003e\n\n    \u003c/a\u003e\n  \n\u003c/h2\u003e\n\u003ch3 id=\"two-stage-architecture\" class=\"scroll-mt-8 group\"\u003e\n  Two-Stage Architecture\n  \n    \u003ca href=\"#two-stage-architecture\"\n        class=\"no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block\"\n        aria-hidden=\"true\" title=\"Link to this heading\" tabindex=\"-1\"\u003e\n        \u003csvg\n  xmlns=\"http://www.w3.org/2000/svg\"\n  width=\"16\"\n  height=\"16\"\n  fill=\"none\"\n  stroke=\"currentColor\"\n  stroke-linecap=\"round\"\n  stroke-linejoin=\"round\"\n  stroke-width=\"2\"\n  class=\"lucide lucide-link w-4 h-4 block\"\n  viewBox=\"0 0 24 24\"\n\u003e\n  \u003cpath d=\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\" /\u003e\n  \u003cpath d=\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\" /\u003e\n\u003c/svg\u003e\n\n    \u003c/a\u003e\n  \n\u003c/h3\u003e\n\u003cp\u003eThe iconic YouTube paper (\u003ca href=\"https://research.google/pubs/deep-neural-networks-for-youtube-recommendations/\"\u003eCovington et al., 2016\u003c/a\u003e) introduced a two-stage architecture that since became the industry standard for large-scale recommender systems:\u003c/p\u003e","tags":[],"title":"Negative Sampling for Learning Two-Tower Networks"},{"categories":["Information retrieval","Multi-task learning"],"date":"2024-07-05T00:00:00Z","id":"/posts/mtml/","keywords":[],"summary":"\u003cp\u003eNatural Language Processing (NLP) has an abundance of intuitively explained tutorials with code, such as Andrej Kaparthy\u0026rsquo;s \u003ca href=\"https://karpathy.ai/zero-to-hero.html\"\u003eNeural Networks: Zero to Hero\u003c/a\u003e, the viral \u003ca href=\"https://jalammar.github.io/illustrated-transformer/\"\u003eThe Illustrated Transformer\u003c/a\u003e and its successor \u003ca href=\"https://nlp.seas.harvard.edu/annotated-transformer/\"\u003eThe Annotated Transformer\u003c/a\u003e, Umar Jamil\u0026rsquo;s YouTube \u003ca href=\"https://www.youtube.com/@umarjamilai\"\u003eseries\u003c/a\u003e dissecting SOTA models and the companion \u003ca href=\"https://github.com/hkproj\"\u003erepo\u003c/a\u003e, among others.\u003c/p\u003e\n\u003cp\u003eWhen it comes to Search/Ads/Recommendations (\u0026ldquo;搜广推\u0026rdquo;), however, intuitive explanations accompanied by code are rare. Company engineering blogs tend to focus on high-level system designs, and many top conference (e.g., KDD/RecSys/SIGIR) papers don\u0026rsquo;t share code. In this post, I explain the iconic Multi-gate Mixture-of-Experts (MMoE) paper (\u003ca href=\"https://dl.acm.org/doi/pdf/10.1145/3219819.3220007\"\u003eMa et al., 2018\u003c/a\u003e) using implementation in the popular \u003ca href=\"https://github.com/shenweichen/DeepCTR-Torch\"\u003eDeepCTR-Torch\u003c/a\u003e repo, to teach myself and readers how the authors\u0026rsquo; blueprint translates into code.\u003c/p\u003e","tags":[],"title":"The Annotated Multi-Task Ranker: An MMoE Code Example"},{"categories":["Embedding","Information retrieval","Vector-based search"],"date":"2024-06-22T00:00:00Z","id":"/posts/ebr/","keywords":[],"summary":"\u003ch2 id=\"so-what-is-an-embedding\" class=\"scroll-mt-8 group\"\u003e\n  So, What is an Embedding?\n  \n    \u003ca href=\"#so-what-is-an-embedding\"\n        class=\"no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block\"\n        aria-hidden=\"true\" title=\"Link to this heading\" tabindex=\"-1\"\u003e\n        \u003csvg\n  xmlns=\"http://www.w3.org/2000/svg\"\n  width=\"16\"\n  height=\"16\"\n  fill=\"none\"\n  stroke=\"currentColor\"\n  stroke-linecap=\"round\"\n  stroke-linejoin=\"round\"\n  stroke-width=\"2\"\n  class=\"lucide lucide-link w-4 h-4 block\"\n  viewBox=\"0 0 24 24\"\n\u003e\n  \u003cpath d=\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\" /\u003e\n  \u003cpath d=\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\" /\u003e\n\u003c/svg\u003e\n\n    \u003c/a\u003e\n  \n\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Embedding\"\u003eEmbedding\u003c/a\u003e is a classic idea in mathematical topology and machine learning (click ▶ for definitions). You can think of embeddings as a special type of vectors.\u003c/p\u003e","tags":[],"title":"An Introduction to Embedding-Based Retrieval"},{"categories":["Machine learning","Natural language processing"],"date":"2024-03-09T00:00:00Z","id":"/posts/attention_as_dict/","keywords":[],"summary":"\u003ch2 id=\"the-dictionary-metaphor-\" class=\"scroll-mt-8 group\"\u003e\n  The Dictionary Metaphor 🔑📚\n  \n    \u003ca href=\"#the-dictionary-metaphor-\"\n        class=\"no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block\"\n        aria-hidden=\"true\" title=\"Link to this heading\" tabindex=\"-1\"\u003e\n        \u003csvg\n  xmlns=\"http://www.w3.org/2000/svg\"\n  width=\"16\"\n  height=\"16\"\n  fill=\"none\"\n  stroke=\"currentColor\"\n  stroke-linecap=\"round\"\n  stroke-linejoin=\"round\"\n  stroke-width=\"2\"\n  class=\"lucide lucide-link w-4 h-4 block\"\n  viewBox=\"0 0 24 24\"\n\u003e\n  \u003cpath d=\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\" /\u003e\n  \u003cpath d=\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\" /\u003e\n\u003c/svg\u003e\n\n    \u003c/a\u003e\n  \n\u003c/h2\u003e\n\u003cp\u003eBy now, the scaled-dot product attention formula might have burned into our brains 🧠, $\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$, yet still this brilliant metaphor from Kevin Murphy\u0026rsquo;s PML book gives it a refreshed interpretation \u0026mdash;\u003c/p\u003e","tags":[],"title":"Attention as Soft Dictionary Lookup"},{"categories":["Search","Information retrieval","Learning to rank"],"date":"2024-02-17T00:00:00Z","id":"/posts/ltr/","keywords":[],"summary":"\u003ch2 id=\"first-thing-first\" class=\"scroll-mt-8 group\"\u003e\n  First Thing First\n  \n    \u003ca href=\"#first-thing-first\"\n        class=\"no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block\"\n        aria-hidden=\"true\" title=\"Link to this heading\" tabindex=\"-1\"\u003e\n        \u003csvg\n  xmlns=\"http://www.w3.org/2000/svg\"\n  width=\"16\"\n  height=\"16\"\n  fill=\"none\"\n  stroke=\"currentColor\"\n  stroke-linecap=\"round\"\n  stroke-linejoin=\"round\"\n  stroke-width=\"2\"\n  class=\"lucide lucide-link w-4 h-4 block\"\n  viewBox=\"0 0 24 24\"\n\u003e\n  \u003cpath d=\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\" /\u003e\n  \u003cpath d=\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\" /\u003e\n\u003c/svg\u003e\n\n    \u003c/a\u003e\n  \n\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003eEnigmas of the universe \u003cbr/\u003e Cannot be known without a search \u003cbr/\u003e \u0026mdash; Epica, \u003ca href=\"https://open.spotify.com/track/34Oz0bzAq7E1aUnKksPfJJ?si=9eabd1446a6a4ccc\"\u003e\u003cem\u003eOmega\u003c/em\u003e\u003c/a\u003e (2021)\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eIn \u003cem\u003e\u003ca href=\"https://en.wikipedia.org/wiki/The_Rainmaker_(1997_film)\"\u003eThe Rainmaker (1997)\u003c/a\u003e\u003c/em\u003e,  the freshly graduated lawyer Rudy Baylor faced off against a giant insurance firm in his debut case, almost getting buried by mountains of case files that the corporate lawyers never expected him to sift through. If only Rudy had a search engine that \u003cem\u003eretrieves\u003c/em\u003e all files mentioning suspicious denials and \u003cem\u003eranks\u003c/em\u003e them from most to least relevant, the case prep would\u0026rsquo;ve been a breeze.\u003c/p\u003e","tags":[],"title":"An Evolution of Learning to Rank"},{"categories":["Search","Information retrieval","Autocomplete"],"date":"2024-01-06T00:00:00Z","id":"/posts/autocomplete/","keywords":[],"summary":"\u003cp\u003eAutocompletion dates back half a century ago (\u003ca href=\"https://www.doc.ic.ac.uk/~shm/MI/mi3.html\"\u003eLonguet-Higgins \u0026amp; Ortony, 1968\u003c/a\u003e), initially designed to save keystrokes as people type and help those with physical disabilities type faster. The incomplete user input is the \u003cstrong\u003e\u0026ldquo;query prefix\u0026rdquo;\u003c/strong\u003e and suggested ways of extending the prefix into a full query are \u003cstrong\u003e\u0026ldquo;query completions\u0026rdquo;\u003c/strong\u003e. This feature is essential to modern text editors and search engines.\u003c/p\u003e\n\u003cfigure\u003e\u003cimg src=\"https://www.dropbox.com/scl/fi/a112bhnp4bctso6fwn72x/Screenshot-2024-01-06-at-4.27.56-PM.png?rlkey=bphpjszgirskda9i142icb5os\u0026amp;raw=1\" width=\"450\"\u003e\n\u003c/figure\u003e\n\n\u003cp\u003eThis blog post summarizes key ideas from the survey paper \u003ca href=\"https://www.nowpublishers.com/article/Details/INR-055\"\u003e\u003cem\u003eA Survey of Query Auto Completion in Information Retrieval\u003c/em\u003e\u003c/a\u003e, recommended by my Search teammate at DoorDash.\u003c/p\u003e","tags":[],"title":"Autocompletion for Search Enginees"},{"categories":["Machine learning"],"date":"2023-07-02T00:00:00Z","id":"/posts/perceptron/","keywords":[],"summary":"\u003cp\u003eTen years after the ImageNet Challenge thawed the last AI winter, ChaptGPT and generative AI have become part of our everyday life and colloquial language, like (almost) no one has imagined just 2 years back. As increasingly more folks aspire to foray into the field of ML/AI, I can\u0026rsquo;t help but think about a lesson from my guitar teacher:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eEveryone wants to start playing the songs they love right off the bat, but without nailing seemingly \u0026ldquo;boring\u0026rdquo; building blocks such as scales, harmonies, and rhythms, the songs you love will sound like a nightmare\u0026hellip;\u003c/p\u003e","tags":[],"title":"Teaching A Peceptron to See"},{"categories":["Machine learning","Algorithms"],"date":"2022-06-22T00:00:00Z","id":"/posts/md_coding/","keywords":[],"summary":"\u003cp\u003eCoding interviews can mean different things for \u0026ldquo;traditional\u0026rdquo; software engineers (back-end, front-end, full-stack, etc.) and engineers with a machine learning focus. Apart from LeetCode-style questions, ML engineers (as well as applied scientists, research engineers, and, occasionally, machine learning data scientists) may be asked to implement a classic ML algorithm from scratch during an interview.\u003c/p\u003e\n\u003cp\u003eThis may sound scary if you\u0026rsquo;ve only used libraries to train models without understanding how learning algorithms work under the hood. Moreover, there are way too many algorithms to memorize. The good news is, only 4 algorithms are commonly asked in interviews: \u003cstrong\u003eLinear regression\u003c/strong\u003e, \u003cstrong\u003elogistic regression\u003c/strong\u003e, \u003cstrong\u003ek-nearest neighbors\u003c/strong\u003e (k-NN), and \u003cstrong\u003ek-means\u003c/strong\u003e. You\u0026rsquo;re probably not gonna code a transformer on the fly in 45 minutes. Let\u0026rsquo;s implement each using vanilla NumPy (and some built-in libraries).\u003c/p\u003e","tags":[],"title":"Code ML Algorithms From Scratch"},{"categories":["Career","Data science","Machine learning","Interview"],"date":"2022-03-13T00:00:00Z","id":"/posts/newgrads/","keywords":[],"summary":"\u003ch2 id=\"new-grad-timeline\" class=\"scroll-mt-8 group\"\u003e\n  New Grad Timeline\n  \n    \u003ca href=\"#new-grad-timeline\"\n        class=\"no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block\"\n        aria-hidden=\"true\" title=\"Link to this heading\" tabindex=\"-1\"\u003e\n        \u003csvg\n  xmlns=\"http://www.w3.org/2000/svg\"\n  width=\"16\"\n  height=\"16\"\n  fill=\"none\"\n  stroke=\"currentColor\"\n  stroke-linecap=\"round\"\n  stroke-linejoin=\"round\"\n  stroke-width=\"2\"\n  class=\"lucide lucide-link w-4 h-4 block\"\n  viewBox=\"0 0 24 24\"\n\u003e\n  \u003cpath d=\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\" /\u003e\n  \u003cpath d=\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\" /\u003e\n\u003c/svg\u003e\n\n    \u003c/a\u003e\n  \n\u003c/h2\u003e\n\u003cp\u003eSince last November, I regularly get questions about how to get data science jobs. I\u0026rsquo;ve hesitated to give advice because no advice applies to everyone. As more people ask, however, I want to write a post for those in my shoes:\u003c/p\u003e","tags":[],"title":"(Quirky) Roadmap for New Grad Data Scientists"},{"categories":["Personal reflections"],"date":"2022-03-04T00:00:00Z","id":"/posts/nothingness/","keywords":[],"summary":"\u003ch2 id=\"seriously-read-the-phd-grind\" class=\"scroll-mt-8 group\"\u003e\n  Seriously, Read \u003cem\u003eThe Ph.D. Grind\u003c/em\u003e\n  \n    \u003ca href=\"#seriously-read-the-phd-grind\"\n        class=\"no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block\"\n        aria-hidden=\"true\" title=\"Link to this heading\" tabindex=\"-1\"\u003e\n        \u003csvg\n  xmlns=\"http://www.w3.org/2000/svg\"\n  width=\"16\"\n  height=\"16\"\n  fill=\"none\"\n  stroke=\"currentColor\"\n  stroke-linecap=\"round\"\n  stroke-linejoin=\"round\"\n  stroke-width=\"2\"\n  class=\"lucide lucide-link w-4 h-4 block\"\n  viewBox=\"0 0 24 24\"\n\u003e\n  \u003cpath d=\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\" /\u003e\n  \u003cpath d=\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\" /\u003e\n\u003c/svg\u003e\n\n    \u003c/a\u003e\n  \n\u003c/h2\u003e\n\u003cp\u003eEveryone doing a Ph.D. or considering doing one should read \u003cem\u003eThe Ph.D. Grind\u003c/em\u003e. Don\u0026rsquo;t wait \u0026mdash; you\u0026rsquo;ll learn the much-needed \u0026ldquo;rational optimism\u0026rdquo; for this crazy ride.\u003c/p\u003e","tags":[],"title":"The Ph.D. Grind: Doing Nothing Is the Hardest Thing"},{"categories":["Causal inference","Quasi-experiment"],"date":"2021-11-12T00:00:00Z","id":"/posts/causality/causality/","keywords":[],"summary":"\u003cp\u003eWhat do you see? 👀\u003c/p\u003e\n\u003cfigure\u003e\u003cimg src=\"https://www.dropbox.com/s/gfiw187r502jb1l/1t1_redgreen_2sec.gif?raw=1\" width=\"350\"\u003e\n\u003c/figure\u003e\n\n\u003cp\u003eYou\u0026rsquo;re probably thinking, \u003cem\u003e\u0026ldquo;The red block stopped, right after which the green block started to move coincidentally.\u0026rdquo;\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eNice try\u0026hellip; I know what you\u0026rsquo;re thinking, \u003cem\u003e\u0026ldquo;The red block \u003cu\u003emade\u003c/u\u003e the green one move\u0026rdquo;\u003c/em\u003e.\u003c/p\u003e\n\u003ch2 id=\"why-ask-why\" class=\"scroll-mt-8 group\"\u003e\n  Why Ask Why?\n  \n    \u003ca href=\"#why-ask-why\"\n        class=\"no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block\"\n        aria-hidden=\"true\" title=\"Link to this heading\" tabindex=\"-1\"\u003e\n        \u003csvg\n  xmlns=\"http://www.w3.org/2000/svg\"\n  width=\"16\"\n  height=\"16\"\n  fill=\"none\"\n  stroke=\"currentColor\"\n  stroke-linecap=\"round\"\n  stroke-linejoin=\"round\"\n  stroke-width=\"2\"\n  class=\"lucide lucide-link w-4 h-4 block\"\n  viewBox=\"0 0 24 24\"\n\u003e\n  \u003cpath d=\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\" /\u003e\n  \u003cpath d=\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\" /\u003e\n\u003c/svg\u003e\n\n    \u003c/a\u003e\n  \n\u003c/h2\u003e\n\u003ch3 id=\"we-cant-help-but-think-about-causation\" class=\"scroll-mt-8 group\"\u003e\n  We can\u0026rsquo;t help but think about causation\n  \n    \u003ca href=\"#we-cant-help-but-think-about-causation\"\n        class=\"no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block\"\n        aria-hidden=\"true\" title=\"Link to this heading\" tabindex=\"-1\"\u003e\n        \u003csvg\n  xmlns=\"http://www.w3.org/2000/svg\"\n  width=\"16\"\n  height=\"16\"\n  fill=\"none\"\n  stroke=\"currentColor\"\n  stroke-linecap=\"round\"\n  stroke-linejoin=\"round\"\n  stroke-width=\"2\"\n  class=\"lucide lucide-link w-4 h-4 block\"\n  viewBox=\"0 0 24 24\"\n\u003e\n  \u003cpath d=\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\" /\u003e\n  \u003cpath d=\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\" /\u003e\n\u003c/svg\u003e\n\n    \u003c/a\u003e\n  \n\u003c/h3\u003e\n\u003cp\u003eYour stats professor can say \u003cem\u003e\u0026ldquo;correlation is not causation\u0026rdquo;\u003c/em\u003e like a broken record, but we can\u0026rsquo;t help but think about causation. Even 12-month-old babies don\u0026rsquo;t think the motions of the two blocks are merely correlated. They look longer, as if \u003cem\u003esurprised\u003c/em\u003e, when we reverse the sequence (but not if the blocks don\u0026rsquo;t abide by Newton\u0026rsquo;s Third Law, in which case the event can\u0026rsquo;t be causal, \u003ca href=\"http://www.jfkominsky.com/demos.html\"\u003eKominsky et al., 2017\u003c/a\u003e). If you\u0026rsquo;re intrigued by causal cognition, I recommend \u003ca href=\"https://youtu.be/q0HLci67Tr8\"\u003ethis talk\u003c/a\u003e by Tobias Gerstenberg.\u003c/p\u003e","tags":[],"title":"Causal Inference in Data Science"},{"categories":["Metrics","Product"],"date":"2021-11-06T00:00:00Z","id":"/posts/metrics/","keywords":[],"summary":"\u003cp\u003e\u0026lsquo;Tis the college and job application season of the year. If only schools and companies have crystal balls to see into each candidate\u0026rsquo;s future achievements, they need not interview people; since they do not have such things, SAT scores, GPA, internships, and other quantifiable metrics are used to aid decisions. Simplified metrics are by no means ideal — As Goodhart put it (often \u003ca href=\"https://en.wikipedia.org/wiki/Goodhart%27s_law\"\u003eparaphrased\u003c/a\u003e), \u0026ldquo;When a measure becomes a metric, it ceases to be a good measure.\u0026rdquo; However, the opposite is worse: Making critical decisions based on heuristics, biases, and personal opinions.\u003c/p\u003e","tags":[],"title":"Choosing Metrics"}]
