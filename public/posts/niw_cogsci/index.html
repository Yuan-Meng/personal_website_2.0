<!doctype html>
<html
  lang="en-us"
  dir="ltr"
>
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    
<link rel="stylesheet" href="http://localhost:1313/css/styles.min.b9043231ddc756d7f5562ab1d7340f4281ad35df8c158a62ccfd66848c674e5e.css">
<meta charset="utf-8" />
<meta name="language" content="en" />
<meta name="viewport" content="width=device-width" />
<title>
    National Importance of Cognitive Science in the AGI Era | Yuan Meng
</title>
  <meta name="description" content=" Dhanasar’s Prong 1: National Importance The life of an immigrant hangs not by a thread, but by a sequence of precisely timed visas and forms: F-1 and I-20 when we accept our PhD offers; OPT/STEM OPT and I-766 when we graduate; H-1B and I-797 when we win the “H-1B lottery”; then I-140, I-485, and eventually the green card. I’ve long given up trying to explain this process to American friends. Even recruiters who make a living by working with candidates of all immigration statuses are often confused by it." />
<meta property="og:url" content="http://localhost:1313/posts/niw_cogsci/">
  <meta property="og:site_name" content="Yuan Meng">
  <meta property="og:title" content="National Importance of Cognitive Science in the AGI Era">
  <meta property="og:description" content="Dhanasar’s Prong 1: National Importance The life of an immigrant hangs not by a thread, but by a sequence of precisely timed visas and forms: F-1 and I-20 when we accept our PhD offers; OPT/STEM OPT and I-766 when we graduate; H-1B and I-797 when we win the “H-1B lottery”; then I-140, I-485, and eventually the green card. I’ve long given up trying to explain this process to American friends. Even recruiters who make a living by working with candidates of all immigration statuses are often confused by it.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2026-02-16T00:00:00+00:00">


  <meta itemprop="name" content="National Importance of Cognitive Science in the AGI Era">
  <meta itemprop="description" content="Dhanasar’s Prong 1: National Importance The life of an immigrant hangs not by a thread, but by a sequence of precisely timed visas and forms: F-1 and I-20 when we accept our PhD offers; OPT/STEM OPT and I-766 when we graduate; H-1B and I-797 when we win the “H-1B lottery”; then I-140, I-485, and eventually the green card. I’ve long given up trying to explain this process to American friends. Even recruiters who make a living by working with candidates of all immigration statuses are often confused by it.">
  <meta itemprop="datePublished" content="2026-02-16T00:00:00+00:00">
  <meta itemprop="wordCount" content="1547">
  <meta itemprop="keywords" content="Cognitive science,Agi,Niw">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="National Importance of Cognitive Science in the AGI Era">
  <meta name="twitter:description" content="Dhanasar’s Prong 1: National Importance The life of an immigrant hangs not by a thread, but by a sequence of precisely timed visas and forms: F-1 and I-20 when we accept our PhD offers; OPT/STEM OPT and I-766 when we graduate; H-1B and I-797 when we win the “H-1B lottery”; then I-140, I-485, and eventually the green card. I’ve long given up trying to explain this process to American friends. Even recruiters who make a living by working with candidates of all immigration statuses are often confused by it.">

<link rel="canonical" href="http://localhost:1313/posts/niw_cogsci/" />

    <link rel="stylesheet" href="/css/index.css" />
    <link rel="stylesheet" href="/css/stranger.css" />


      <script src="/js/main.js" defer></script>
  

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org/",
  "@id": "http://localhost:1313/posts/niw_cogsci/",
  "@type": "BlogPosting",
  "articleSection": [
    "Cognitive science",
    "Agi",
    "Niw"
  ],
  "author": {
    "@type": "Person",
    "email": "mycaptainmy@gmail.com",
    "name": "Yuan Meng",
    "url": "http://localhost:1313/about/"
  },
  "copyrightNotice": "Yuan Meng",
  "datePublished": "2026-02-16",
  "description": " Dhanasar’s Prong 1: National Importance The life of an immigrant hangs not by a thread, but by a sequence of precisely timed visas and forms: F-1 and I-20 when we accept our PhD offers; OPT/STEM OPT and I-766 when we graduate; H-1B and I-797 when we win the “H-1B lottery”; then I-140, I-485, and eventually the green card. I’ve long given up trying to explain this process to American friends. Even recruiters who make a living by working with candidates of all immigration statuses are often confused by it.",
  "headline": "National Importance of Cognitive Science in the AGI Era",
  "isPartOf": {
    "@id": "http://localhost:1313/posts/",
    "@type": "Blog",
    "name": "Posts"
  },
  "mainEntityOfPage": "http://localhost:1313/posts/niw_cogsci/",
  "name": "National Importance of Cognitive Science in the AGI Era",
  "timeRequired": "PT8M",
  "url": "http://localhost:1313/posts/niw_cogsci/",
  "wordCount": 1547
}
</script>


  </head>
  <body>
    <div class="container mx-auto flex max-w-prose flex-col space-y-10 p-4 md:p-6">
      <header class="flex flex-row items-center justify-between">
        <div>
  <a id="skip-nav" class="sr-only" href="#maincontent">Skip to main content</a>
  <a class="font-semibold" href="/">Yuan Meng</a>
</div>

  <nav>
    <ul class="flex flex-row items-center justify-end space-x-4">
    <li>
      <a href="/about/">About</a
      >
    </li>
    <li>
      <a aria-current="true" class="ancestor" href="/posts/">Posts</a
      >
    </li>
    <li>
      <a href="/notes/">Notes</a
      >
    </li>
    </ul>
  </nav>


      </header>
      <main class="prose prose-slate relative md:prose-lg prose-h1:text-[2em]" id="maincontent">
        <article class="main">
    <header>
      <h1 class="!mb-1">National Importance of Cognitive Science in the AGI Era</h1><div class="flex flex-row items-center space-x-4">
          <time class="text-sm italic opacity-80" datetime="2026-02-16T00:00:00&#43;00:00">February 16, 2026</time>
        </div>
    </header>

    
    
      Reading time: 8 minutes
    

    
    
      <div class="toc-container">
        <span id="toc-toggle">
          <span id="toc-icon">▶</span> 
          <span>Table of Contents</span>
        </span>
        <nav id="TableOfContents" class="toc-content">
          <nav id="TableOfContents">
  <ul>
    <li><a href="#dhanasars-prong-1-national-importance">Dhanasar&rsquo;s Prong 1: National Importance</a></li>
    <li><a href="#what-cogsci-has-to-say-about-ai">What CogSci Has to Say About AI</a>
      <ul>
        <li><a href="#contributions-by-domain">Contributions by Domain</a>
          <ul>
            <li><a href="#ai-that-reasons-to-act">AI that Reasons to Act</a></li>
            <li><a href="#ai-that-is-fair--unbiased">AI That is Fair &amp; Unbiased</a></li>
            <li><a href="#ai-with-physical-intuitions">AI with Physical Intuitions</a></li>
          </ul>
        </li>
        <li><a href="#contributions-by-methodology">Contributions by Methodology</a>
          <ul>
            <li><a href="#benchmarks-for-human--machine-learners">Benchmarks for Human + Machine Learners</a></li>
            <li><a href="#scaffold-human--machine-learning">Scaffold Human + Machine Learning</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#carry-on-cogsci-research-in-industry">Carry On CogSci Research in Industry</a>
      <ul>
        <li><a href="#recsys-as-the-playground-for-ai-agents">RecSys as the Playground for AI Agents</a></li>
        <li><a href="#reach-out-to-institutes-and-benchmark-creators">Reach out to Institutes and Benchmark Creators</a></li>
      </ul>
    </li>
    <li><a href="#resources--inspirations">Resources + Inspirations</a>
      <ul>
        <li><a href="#ai--cogsci-researchers-to-follow">AI + CogSci Researchers to Follow</a></li>
        <li><a href="#papers-talks-and-inspiring-words">Papers, Talks, and Inspiring Words</a></li>
        <li><a href="#writing-guide-for-national-importance">Writing Guide for National Importance</a></li>
      </ul>
    </li>
  </ul>
</nav>
        </nav>
      </div>

      <script>
        
        document.addEventListener('DOMContentLoaded', function () {
          var tocToggle = document.getElementById('toc-toggle');
          var tocContent = document.getElementById('TableOfContents');
          var tocIcon = document.getElementById('toc-icon');
          tocToggle.addEventListener('click', function () {
            if (tocContent.style.display === 'none' || tocContent.style.display === '') {
              tocContent.style.display = 'block';
              tocIcon.textContent = '▼'; 
            } else {
              tocContent.style.display = 'none';
              tocIcon.textContent = '▶'; 
            }
          });
        });
      </script>
    

    
    <div class="content">
      <h2 id="dhanasars-prong-1-national-importance" class="scroll-mt-8 group">
  Dhanasar&rsquo;s Prong 1: National Importance
  
    <a href="#dhanasars-prong-1-national-importance"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h2>
<p>The life of an immigrant hangs not by a thread, but by a sequence of precisely timed visas and forms: F-1 and I-20 when we accept our PhD offers; OPT/STEM OPT and I-766 when we graduate; H-1B and I-797 when we win the &ldquo;H-1B lottery&rdquo;; then I-140, I-485, and eventually the green card. I&rsquo;ve long given up trying to explain this process to American friends. Even recruiters who make a living by working with candidates of all immigration statuses are often confused by it.</p>
<p>As a result of tech layoffs, labor market testing needed for <a href="https://forumtogether.org/article/explainer-perm-labor-certification-process/">PERM</a> certifications is getting increasingly harder to pass. For many of us, the only alternative is to show the national importance of our work and obtain a National Interest Waiver (<a href="https://www.uscis.gov/newsroom/alerts/uscis-updates-guidance-on-eb-2-national-interest-waiver-petitions">NIW</a>). Dr. Dhanasar and his team fought hard in 2016 to set the current standard (<a href="https://www.justice.gov/eoir/page/file/920996/dl"><em>Matter of Dhanasar</em></a>).</p>
<p>For many of us, &ldquo;national importance&rdquo; is not an afterthought we&rsquo;re scrambling together for the sake of NIW, but why we decided to pursue a PhD in the first place &mdash; we believed our work mattered to humanity, not just one nation. I did when I dreamt of becoming a cognitive scientist, believing my field held the key to what makes us human and how intelligence comes to be. I chose a tech career because it better suited my personality and goals &mdash; it doesn&rsquo;t make my past research any less important. Moreover, I see the NIW petition as a fun challenge to think of future research I can realistically pursue to advance CogSci + AI &mdash; now that I&rsquo;m a bit older, hopefully wiser, and know a lot more about AI/ML than when I was a CogSci PhD student.</p>
<!-- I can't do anything unless I believe in its meaning. For instance, I can't prepare for interviews unless I believe it makes me a better engineer. Similarly, I can't prepare for an NIW case unless I believe what I've done or am about to do has national importance. So I often go a long way in search of that meaning, including spending an insane number of hours reading and thinking about ML engineering for interviews, and in this case, cognitively inspired AI for NIW --- even though there are many shortcuts to take (e.g., memorizing answers to common interview questions, or sketching out a seemingly reasonable research agenda that has little chance of becoming real). This need to believe makes me who I am and is the motivation behind this blogpost. -->
<p>There are many great NIW examples in the natural sciences &mdash; check out chemist Andrey Solovyev&rsquo;s informative <a href="https://andreychemist.github.io/">I-140 website</a>! As far as I know, this post may be the first related to CogSci NIW petitions. This is a WIP &mdash; I&rsquo;ll update it as I think of more ways CogSci informs AGI.</p>
<h2 id="what-cogsci-has-to-say-about-ai" class="scroll-mt-8 group">
  What CogSci Has to Say About AI
  
    <a href="#what-cogsci-has-to-say-about-ai"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h2>
<blockquote>
<p>&ldquo;An important feature of a learning machine is that its teacher will often be very largely ignorant of quite what is going on inside, although he may still be able to some extent to predict his pupil&rsquo;s behavior.&rdquo; &mdash; Alan Turing, <a href="https://courses.cs.umbc.edu/471/papers/turing.pdf">Computing Machinery and Intelligence</a> (1950)</p>
</blockquote>
<p>On April Fool&rsquo;s Day in 2019, when I was in grad school, I put together a fake newspaper article claiming &ldquo;AI has achieved the intelligence of a 5-year-old&rdquo; and shared it in Prof. <a href="https://www.alisongopnik.com/">Alison Gopnik</a>&rsquo;s <a href="https://www.edge.org/conversation/alison_gopnik-possible-minds-25-ways-of-looking-at-ai"><em>Possible Minds</em></a> seminar. A split second of shock turned into five seconds of laughter.</p>
<p>My practical joke landed because even the best &ldquo;AGI&rdquo; felt wildly unhuman-like at the time. <a href="https://en.wikipedia.org/wiki/GPT-2">GPT-2</a> had just come out two months earlier, and we were already amazed how it could generate 3 pages of somewhat coherent text, even though the content was often nonsensical. It was hard to imagine how any AI could ever resemble any 5-year-old&rsquo;s creativity and learning abilities in any shape or form.</p>
<p>Fast forward to today, the tide has completely turned. After skimming new papers by cognitive scientists and AI researchers with deep CogSci roots (e.g., <a href="https://www.arxiv.org/abs/2602.06176"><em>Large Language Model Reasoning Failures</em></a>), it feels like many researchers now afford large language models the same respect they give human children and adults. LLMs are treated as yet another (black-box) intelligence. Researchers probe their reasoning and ethical failures the way they study humans, and try to mitigate those failures by steering behavior with small amounts of data (e.g., prompting, SFT, RLHF), rather than going through pretraining/evolution again. Five-year-old intelligence was a punchline. Now it&rsquo;s probably a baseline.</p>
<h3 id="contributions-by-domain" class="scroll-mt-8 group">
  Contributions by Domain
  
    <a href="#contributions-by-domain"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<p>A central question in CogSci is: <em>how can humans (infants + children + adults) learn so much from so little, so quickly?</em></p>
<p>Since the early 2000s, a view popularized by Josh Tenenbaum, Tom Griffiths, and colleagues is that:
(1) humans don&rsquo;t consider all possible hypotheses (e.g., we don&rsquo;t search the ceiling for our glasses) &mdash; instead, we rely on rich prior knowledge to narrow the hypothesis space (e.g., desk, sofa, under the bed); and (2) once new data is observed, it percolates through hierarchical Bayesian models to update more abstract beliefs (e.g., search first where we last used the object).</p>
<p>Papers expressing the above view are too many to name. For a quick overview, read <a href="https://cocosci.princeton.edu/tom/papers/LabPublications/GrowMind.pdf"><em>How to Grow a Mind</em></a>. For a comprehensive treatment, read the finally published <a href="https://mitpress.mit.edu/9780262049412/bayesian-models-of-cognition/"><em>Bayesian Models of Cognition</em></a> by the OGs. Norvig and Russell&rsquo;s <a href="https://aima.cs.berkeley.edu/"><em>Artificial Intelligence: A Modern Approach</em></a> is not a CogSci book but it mirrors domains traditionally studied in CogSci.</p>
<p>My crude take is this: much of CogSci studies what looks like &ldquo;post-training&rdquo; and &ldquo;prompt engineering&rdquo; in AI. The human mind is pretrained, by evolution and development, and therefore comes with strong priors. That&rsquo;s why we can learn quickly from so little data &mdash; nothing magical, but because most of the knowledge is already there. What we call &ldquo;learning&rdquo; in CogSci experiments either exposes or updates prior knowledge rather than redoing pretraining from scratch.</p>
<p>If this view holds, where CogSci can contribute the most to AI is post-training and prompting. By identifying the priors humans rely on in different domains, we can design post-training or prompting strategies that compensate for gaps in current models &mdash; especially where AI still struggles but humans learn effortlessly. Below are some examples.</p>
<h4 id="ai-that-reasons-to-act" class="scroll-mt-8 group">
  AI that Reasons to Act
  
    <a href="#ai-that-reasons-to-act"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<p>When I was preparing for OpenAI interviews, I made a list of must-read papers for applied AI. <a href="https://arxiv.org/abs/2210.03629">ReAct</a> was the second paper I read (after the <a href="https://arxiv.org/abs/2005.11401">RAG</a> paper). It sets the foundations for modern language agents and reasoning models. This work instantly pulled me back to grad school memories, especially years spent on studying explanation (e.g., <a href="https://cognition.princeton.edu/publications/inference-best-explanation-ibe-versus-explaining-best-inference-ebi">Wilkenfeld &amp; Lombrozo, 2015</a>), information seeking (e.g., <a href="https://www.cs.princeton.edu/~bl8144/papers/RotheEtAl2018CompBrainBehavior.pdf">Rothe, Lake, &amp; Gureckis, 2018</a>), and how explanation and information seeking reinforce one another (e.g., <a href="https://proceedings.mlr.press/v162/lampinen22a/lampinen22a.pdf">Lampinen et al., 2022</a> and <a href="https://www.proquest.com/openview/9886c692bc27fcb566ef80fd54820735/1?pq-origsite=gscholar&amp;cbl=18750&amp;diss=y">my dissertation</a>).</p>
<figure><img src="https://www.dropbox.com/scl/fi/2px3uq6t19uj2tn28xhtr/Screenshot-2026-02-09-at-8.49.48-PM.png?rlkey=ahxp5hywwqrkd7visrgg2l5pu&amp;st=hted00yq&amp;raw=1"
    alt="A ReAct agent interleaves reasoning and acting to get to correct answers fact." width="1800"><figcaption>
      <p>A <a href="https://arxiv.org/abs/2210.03629">ReAct</a> agent interleaves reasoning and acting to get to correct answers fact.</p>
    </figcaption>
</figure>

<p>Given a task with many possible outcomes (e.g., locations of a pepper shaker), some better than others (finding the shaker than not finding it), a language agent can reason about plans (likely places to search) or observations (e.g., findings from a search), and execute actions, reason about new observations, and revise plans accordingly. These are what humans &mdash; including adults and children &mdash; in everyday life.</p>
<p>Like CogSci papers, ReAct first reads incredibly interesting because it makes so much intuitive sense, and then the aftertaste comes incredibly boring because both LLMs and humans are pretrained &mdash; it feels like the fun is at the pretraining party. Thinking yet again, however, how to elicit knowledge from a pretrained intelligence so it can do what it never was able to do is amazing, useful, if not a bit mysterious. If I wanted to study how a mind becomes to be, I&rsquo;d probably study evolution instead of CogSci in the first place.</p>
<p>how cogsci contributes</p>
<ul>
<li>
<p>ask for causal explanations?</p>
</li>
<li>
<p>recsys as environment for language agents to reason and act &ndash; webshop benchmark</p>
</li>
<li>
<p>web-scale recommender systems as the playground for agents with human priors</p>
</li>
<li>
<p>frame recsys as web interaction</p>
</li>
</ul>
<p>what i can contribute:
more realistic benchmarks based on real recsys
teach agents to reason better, so in term, they can use better reasoning to act better</p>
<p><a href="https://peiyang-song.github.io/">https://peiyang-song.github.io/</a>
<a href="https://github.com/google/BIG-bench">https://github.com/google/BIG-bench</a></p>
<!-- shunyu said second half of LLM is rl
andrej said 2025 was the year of agent that never was
clue game
 -->
<h4 id="ai-that-is-fair--unbiased" class="scroll-mt-8 group">
  AI That is Fair &amp; Unbiased
  
    <a href="#ai-that-is-fair--unbiased"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<h4 id="ai-with-physical-intuitions" class="scroll-mt-8 group">
  AI with Physical Intuitions
  
    <a href="#ai-with-physical-intuitions"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<p>world models</p>
<h3 id="contributions-by-methodology" class="scroll-mt-8 group">
  Contributions by Methodology
  
    <a href="#contributions-by-methodology"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<h4 id="benchmarks-for-human--machine-learners" class="scroll-mt-8 group">
  Benchmarks for Human + Machine Learners
  
    <a href="#benchmarks-for-human--machine-learners"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<p>SOTA model paired by old cognitive tasks
cite Baddley
collab with LMArena</p>
<h4 id="scaffold-human--machine-learning" class="scroll-mt-8 group">
  Scaffold Human + Machine Learning
  
    <a href="#scaffold-human--machine-learning"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<p>can&rsquo;t get IRB approval. so studying LLMs may be a good way</p>
<h2 id="carry-on-cogsci-research-in-industry" class="scroll-mt-8 group">
  Carry On CogSci Research in Industry
  
    <a href="#carry-on-cogsci-research-in-industry"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h2>
<p>i used to joke that every road leads to recsys
many fellow cogsci students became recsys mle
upon reflection, it&rsquo;s not a coincidence
it&rsquo;s because recsys is important in life &ndash; economy politics entertainment
moreover recsys is a great way to train and deploy agents that will play a part in our lives</p>
<h3 id="recsys-as-the-playground-for-ai-agents" class="scroll-mt-8 group">
  RecSys as the Playground for AI Agents
  
    <a href="#recsys-as-the-playground-for-ai-agents"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<p>WebShop: item-first search</p>
<ul>
<li>RecSys is important and realistic for training, testing, and deploying AI agents</li>
</ul>
<h3 id="reach-out-to-institutes-and-benchmark-creators" class="scroll-mt-8 group">
  Reach out to Institutes and Benchmark Creators
  
    <a href="#reach-out-to-institutes-and-benchmark-creators"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<p>LMArena</p>
<h2 id="resources--inspirations" class="scroll-mt-8 group">
  Resources + Inspirations
  
    <a href="#resources--inspirations"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h2>
<h3 id="ai--cogsci-researchers-to-follow" class="scroll-mt-8 group">
  AI + CogSci Researchers to Follow
  
    <a href="#ai--cogsci-researchers-to-follow"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<p>many ai researchers in prev gen have cogsci training
nowadays rare</p>
<ul>
<li><strong>All Things Cognitively Inspired AI</strong>: <a href="https://scholar.google.com/citations?user=JicYPdAAAAAJ&amp;hl=en">Geoff Hinton</a>, <a href="https://scholar.google.com/citations?hl=en&amp;user=rRJ9wTJMUB8C&amp;view_op=list_works&amp;sortby=pubdate">Josh Tenenbaum</a>, <a href="https://cocosci.princeton.edu/publications.php">Tom Griffiths</a>, <a href="https://cocolab.stanford.edu/publications">Noah Goodman</a>, <a href="https://colala.berkeley.edu/">Steve Piantadosi</a>, <a href="https://www.cs.princeton.edu/~bl8144/">Brenden Lake</a>, <a href="https://gershmanlab.com/pubs.html">Sam Gershman</a></li>
<li><strong>Agents and reasoning</strong>: <a href="https://ysymyth.github.io/">Shunyu Yao</a>, <a href="https://scholar.google.com/citations?hl=en&amp;user=_N44XxAAAAAJ&amp;view_op=list_works&amp;sortby=pubdate">Andrew Lampien</a>, <a href="https://cognition.princeton.edu/publications">Tania Lombrozo</a>, <a href="https://elc-lab-ucsd.com/publications">Caren Walker</a>, <a href="https://ccdlab.hsites.harvard.edu/publications">Elizabeth Bonawitz</a>, <a href="https://www.gureckislab.org/papers">Todd Gureckis</a></li>
<li><strong>Social cognition</strong>: <a href="https://scholar.google.com/citations?user=zjl9R-oAAAAJ&amp;hl=en">Hyowon Gweon</a>, <a href="https://compdevlab.yale.edu/publications.html">Julian Jara-Ettinger</a>, <a href="https://ccs-ucb.github.io/publications.html">Bill Thompson</a>, <a href="https://baixuechunzi.github.io/uchicago/publications.html">Xuechunzi Bai</a>, <a href="https://www.alancowen.com/publications">Alan Cowen</a>, <a href="https://scholar.google.com/citations?user=SACXQKYAAAAJ&amp;hl=en">Max Kleiman-Weiner</a></li>
<li><strong>Intuitive physics and &ldquo;World Models&rdquo;</strong>: <a href="https://profiles.stanford.edu/fei-fei-li">Fei-Fei Li</a>, <a href="http://yann.lecun.com/">Yann Lecun</a>, <a href="https://jiajunwu.com/">Jiajun Wu</a>, <a href="https://scholar.google.com/citations?user=5SF-hRsAAAAJ&amp;hl=en">Tomer Ullman</a>, <a href="https://www.jesshamrick.com/papers/">Jessica Hamrick</a>, <a href="https://www.mit.edu/~k2smith/">Kevin Smith</a></li>
</ul>
<h3 id="papers-talks-and-inspiring-words" class="scroll-mt-8 group">
  Papers, Talks, and Inspiring Words
  
    <a href="#papers-talks-and-inspiring-words"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<ul>
<li>
<p>Opinions on CogSci + AI: Jay McClelland&rsquo;s <a href="https://news.stanford.edu/stories/2024/11/from-brain-to-machine-the-unexpected-journey-of-neural-networks">interview</a>, Reddit <a href="https://www.reddit.com/r/MachineLearning/comments/10wtumf/discussion_cognitive_science_inspired_ai_research/">post</a></p>
</li>
<li>
<p>How neural nets learn to generalize: <a href="https://arxiv.org/abs/2309.02390"><em>Explaining Grokking through Circuit Efficiency</em></a></p>
</li>
<li>
<p>RecSys + reasoning: <a href="https://recsysml.substack.com/p/stop-predicting-ctr-start-optimizing">RL-aligned ranking</a></p>
</li>
<li>
<p><a href="https://youtu.be/d95J8yzvjbQ?si=sPyAYlANyfm4RewK"><em>The Thinking Game</em></a>, a documentary on DeepMind CEO Demis Hassabis&rsquo; life and search for AGI</p>
</li>
<li>
<p>Shunyu yao&rsquo;s dissertation</p>
</li>
<li>
<p><a href="https://ysymyth.github.io/The-Second-Half/">https://ysymyth.github.io/The-Second-Half/</a></p>
</li>
<li>
<p><a href="https://karpathy.bearblog.dev/year-in-review-2025/">https://karpathy.bearblog.dev/year-in-review-2025/</a></p>
</li>
<li>
<p><a href="https://www.youtube.com/watch?v=ff-ip0A40ks">https://www.youtube.com/watch?v=ff-ip0A40ks</a></p>
</li>
<li>
<p><a href="https://www.youtube.com/watch?v=YBVlVlBWQhs">https://www.youtube.com/watch?v=YBVlVlBWQhs</a></p>
</li>
<li>
<p><a href="https://www.youtube.com/watch?v=46A-BcBbMnA">https://www.youtube.com/watch?v=46A-BcBbMnA</a></p>
</li>
<li>
<p><a href="https://runzhe-yang.science/2023-05-05-socratic/">https://runzhe-yang.science/2023-05-05-socratic/</a></p>
</li>
</ul>
<h3 id="writing-guide-for-national-importance" class="scroll-mt-8 group">
  Writing Guide for National Importance
  
    <a href="#writing-guide-for-national-importance"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<ul>
<li>Reddit posts: <a href="https://www.reddit.com/r/EB2_NIW/comments/1oygx31/substantial_merit_vs_national_importance_of_your/"><em>Substantial Merit vs National Importance of your EB-2 NIW Proposed Endeavor</em></a></li>
<li>Xiaohongshu posts on NIW writing tips: examples <a href="https://www.xiaohongshu.com/discovery/item/696f38fb000000000a02b8ea?source=webshare&amp;xhsshare=pc_web&amp;xsec_token=ABlkwa_GCrUBYzvCNgrH81ExLJiQLrld6J8Uu--uJQ9_M=&amp;xsec_source=pc_share">1</a>, <a href="https://www.xiaohongshu.com/discovery/item/6966946c000000000e00d8b1?source=webshare&amp;xhsshare=pc_web&amp;xsec_token=ABxzZX4CErOzETZ99sJ5szWXnlhqJwZUXLBMyIly__K3U=&amp;xsec_source=pc_share">2</a>, <a href="https://www.xiaohongshu.com/discovery/item/6966946c000000000e00d8b1?source=webshare&amp;xhsshare=pc_web&amp;xsec_token=ABxzZX4CErOzETZ99sJ5szWXnlhqJwZUXLBMyIly__K3U=&amp;xsec_source=pc_share">3</a>, <a href="https://www.xiaohongshu.com/discovery/item/696e3c0d000000001a023a81?source=webshare&amp;xhsshare=pc_web&amp;xsec_token=ABgpq_DuFyBr3YMDGiTGmvr7QUvc5RW3xeCf_M25pGr4E=&amp;xsec_source=pc_share">4</a></li>
<li>Grant proposals: how professors ask governments for money
<ul>
<li>STEM education: <a href="https://ecrhub.org/ecr-projects?id=2400757">NSF #2400757</a>, <a href="https://www.nsf.gov/awardsearch/show-award/?AWD_ID=1640816">NSF #1640816</a></li>
</ul>
</li>
</ul>
<!-- continuing impact
- blogpost
- read my papers
- thank you emails & linkedin messages -->
    </div>
  </article>

  
    <aside class="not-prose flex flex-col space-y-8 border-t pt-6">
    <section class="flex flex-col space-y-4">
      <h2 class="flex flex-row items-center space-x-2 text-lg font-semibold">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-shapes h-4 w-4"
  viewBox="0 0 24 24"
  aria-hidden="true"
>
  <path
    d="M8.3 10a.7.7 0 0 1-.626-1.079L11.4 3a.7.7 0 0 1 1.198-.043L16.3 8.9a.7.7 0 0 1-.572 1.1Z"
  />
  <rect width="7" height="7" x="3" y="14" rx="1" />
  <circle cx="17.5" cy="17.5" r="3.5" />
</svg>

        <span>Categories</span>
      </h2>

      <ul class="ml-6 flex flex-row flex-wrap items-center space-x-2">
          <li>
            <a href="/categories/cognitive-science/" class="taxonomy category">cognitive science</a>
          </li>
          <li>
            <a href="/categories/agi/" class="taxonomy category">agi</a>
          </li>
          <li>
            <a href="/categories/niw/" class="taxonomy category">niw</a>
          </li>
      </ul>
    </section>
    <section class="flex flex-col space-y-4" aria-hidden="true">
      <h2 class="flex flex-row items-center space-x-2 text-lg font-semibold">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-chart-network h-4 w-4"
  viewBox="0 0 24 24"
  aria-hidden="true"
>
  <path
    d="m13.11 7.664 1.78 2.672M14.162 12.788l-3.324 1.424M20 4l-6.06 1.515M3 3v16a2 2 0 0 0 2 2h16"
  />
  <circle cx="12" cy="6" r="2" />
  <circle cx="16" cy="12" r="2" />
  <circle cx="9" cy="15" r="2" />
</svg>

        <span>Graph</span>
      </h2>

      <content-network-graph
  class="h-64 ml-6"
  data-endpoint="/graph/index.json"
  page="/posts/niw_cogsci/"
></content-network-graph>

    </section>
</aside>

      </main>
      <footer class="mt-20 border-t border-neutral-100 pt-2 text-xs">
        
<section class="items-top flex flex-row justify-between opacity-70">
  <div class="flex flex-col space-y-2">
      <p>Copyright &copy; 2026, Yuan Meng.</p>
      <div
        xmlns:cc="https://creativecommons.org/ns#"
        xmlns:dct="http://purl.org/dc/terms/"
        about="https://creativecommons.org"
      >
        Content is available under
        <a href="https://creativecommons.org/licenses/by-sa/4.0/" rel="license" class="inline-block" title="Creative Commons Attribution-ShareAlike 4.0 International"
          >CC BY-SA 4.0</a
        >
        unless otherwise noted.
      </div>
        <div
          class="mt-2 flex items-center space-x-2 fill-slate-400 hover:fill-slate-600 motion-safe:transition-colors"
        >
          <div class="flex-none cursor-help"><svg
  version="1.0"
  xmlns="http://www.w3.org/2000/svg"
  viewBox="5.5 -3.5 64 64"
  xml:space="preserve"
  class="w-5 h-5 block"
  aria-hidden="true"
>
  <title>Creative Commons</title>
  <circle fill="transparent" cx="37.785" cy="28.501" r="28.836" />
  <path
    d="M37.441-3.5c8.951 0 16.572 3.125 22.857 9.372 3.008 3.009 5.295 6.448 6.857 10.314 1.561 3.867 2.344 7.971 2.344 12.314 0 4.381-.773 8.486-2.314 12.313-1.543 3.828-3.82 7.21-6.828 10.143-3.123 3.085-6.666 5.448-10.629 7.086-3.961 1.638-8.057 2.457-12.285 2.457s-8.276-.808-12.143-2.429c-3.866-1.618-7.333-3.961-10.4-7.027-3.067-3.066-5.4-6.524-7-10.372S5.5 32.767 5.5 28.5c0-4.229.809-8.295 2.428-12.2 1.619-3.905 3.972-7.4 7.057-10.486C21.08-.394 28.565-3.5 37.441-3.5zm.116 5.772c-7.314 0-13.467 2.553-18.458 7.657-2.515 2.553-4.448 5.419-5.8 8.6a25.204 25.204 0 0 0-2.029 9.972c0 3.429.675 6.734 2.029 9.913 1.353 3.183 3.285 6.021 5.8 8.516 2.514 2.496 5.351 4.399 8.515 5.715a25.652 25.652 0 0 0 9.943 1.971c3.428 0 6.75-.665 9.973-1.999 3.219-1.335 6.121-3.257 8.713-5.771 4.99-4.876 7.484-10.99 7.484-18.344 0-3.543-.648-6.895-1.943-10.057-1.293-3.162-3.18-5.98-5.654-8.458-5.146-5.143-11.335-7.715-18.573-7.715zm-.401 20.915-4.287 2.229c-.458-.951-1.019-1.619-1.685-2-.667-.38-1.286-.571-1.858-.571-2.856 0-4.286 1.885-4.286 5.657 0 1.714.362 3.084 1.085 4.113.724 1.029 1.791 1.544 3.201 1.544 1.867 0 3.181-.915 3.944-2.743l3.942 2c-.838 1.563-2 2.791-3.486 3.686-1.484.896-3.123 1.343-4.914 1.343-2.857 0-5.163-.875-6.915-2.629-1.752-1.752-2.628-4.19-2.628-7.313 0-3.048.886-5.466 2.657-7.257 1.771-1.79 4.009-2.686 6.715-2.686 3.963-.002 6.8 1.541 8.515 4.627zm18.457 0-4.229 2.229c-.457-.951-1.02-1.619-1.686-2-.668-.38-1.307-.571-1.914-.571-2.857 0-4.287 1.885-4.287 5.657 0 1.714.363 3.084 1.086 4.113.723 1.029 1.789 1.544 3.201 1.544 1.865 0 3.18-.915 3.941-2.743l4 2c-.875 1.563-2.057 2.791-3.541 3.686a9.233 9.233 0 0 1-4.857 1.343c-2.896 0-5.209-.875-6.941-2.629-1.736-1.752-2.602-4.19-2.602-7.313 0-3.048.885-5.466 2.658-7.257 1.77-1.79 4.008-2.686 6.713-2.686 3.962-.002 6.783 1.541 8.458 4.627z"
  />
</svg>
</div><div class="flex-none cursor-help"><svg
  version="1.0"
  xmlns="http://www.w3.org/2000/svg"
  viewBox="5.5 -3.5 64 64"
  xml:space="preserve"
  class="w-5 h-5 block"
>
  <title>Credit must be given to the creator</title>
  <circle fill="transparent" cx="37.637" cy="28.806" r="28.276" />
  <path
    d="M37.443-3.5c8.988 0 16.57 3.085 22.742 9.257C66.393 11.967 69.5 19.548 69.5 28.5c0 8.991-3.049 16.476-9.145 22.456-6.476 6.363-14.113 9.544-22.912 9.544-8.649 0-16.153-3.144-22.514-9.43C8.644 44.784 5.5 37.262 5.5 28.5c0-8.761 3.144-16.342 9.429-22.742C21.101-.415 28.604-3.5 37.443-3.5zm.114 5.772c-7.276 0-13.428 2.553-18.457 7.657-5.22 5.334-7.829 11.525-7.829 18.572 0 7.086 2.59 13.22 7.77 18.398 5.181 5.182 11.352 7.771 18.514 7.771 7.123 0 13.334-2.607 18.629-7.828 5.029-4.838 7.543-10.952 7.543-18.343 0-7.276-2.553-13.465-7.656-18.571-5.104-5.104-11.276-7.656-18.514-7.656zm8.572 18.285v13.085h-3.656v15.542h-9.944V33.643h-3.656V20.557c0-.572.2-1.057.599-1.457.401-.399.887-.6 1.457-.6h13.144c.533 0 1.01.2 1.428.6.417.4.628.886.628 1.457zm-13.087-8.228c0-3.008 1.485-4.514 4.458-4.514s4.457 1.504 4.457 4.514c0 2.971-1.486 4.457-4.457 4.457s-4.458-1.486-4.458-4.457z"
  />
</svg>
</div><div class="flex-none cursor-help"><svg
  version="1.0"
  xmlns="http://www.w3.org/2000/svg"
  viewBox="5.5 -3.5 64 64"
  xml:space="preserve"
  class="w-5 h-5 block"
>
  <title>Adaptations must be shared under the same terms</title>
  <circle fill="transparent" cx="36.944" cy="28.631" r="29.105" />
  <path
    d="M37.443-3.5c8.951 0 16.531 3.105 22.742 9.315C66.393 11.987 69.5 19.548 69.5 28.5c0 8.954-3.049 16.457-9.145 22.514-6.437 6.324-14.076 9.486-22.912 9.486-8.649 0-16.153-3.143-22.514-9.429C8.644 44.786 5.5 37.264 5.5 28.501c0-8.723 3.144-16.285 9.429-22.685C21.138-.395 28.643-3.5 37.443-3.5zm.114 5.772c-7.276 0-13.428 2.572-18.457 7.715-5.22 5.296-7.829 11.467-7.829 18.513 0 7.125 2.59 13.257 7.77 18.4 5.181 5.182 11.352 7.771 18.514 7.771 7.123 0 13.334-2.609 18.629-7.828 5.029-4.876 7.543-10.99 7.543-18.343 0-7.313-2.553-13.485-7.656-18.513-5.067-5.145-11.239-7.715-18.514-7.715zM23.271 23.985c.609-3.924 2.189-6.962 4.742-9.114 2.552-2.152 5.656-3.228 9.314-3.228 5.027 0 9.029 1.62 12 4.856 2.971 3.238 4.457 7.391 4.457 12.457 0 4.915-1.543 9-4.627 12.256-3.088 3.256-7.086 4.886-12.002 4.886-3.619 0-6.743-1.085-9.371-3.257-2.629-2.172-4.209-5.257-4.743-9.257H31.1c.19 3.886 2.533 5.829 7.029 5.829 2.246 0 4.057-.972 5.428-2.914 1.373-1.942 2.059-4.534 2.059-7.771 0-3.391-.629-5.971-1.885-7.743-1.258-1.771-3.066-2.657-5.43-2.657-4.268 0-6.667 1.885-7.2 5.656h2.343l-6.342 6.343-6.343-6.343 2.512.001z"
  />
</svg>
</div>
        </div>

  </div>
    <div>
      <a
        href="https://github.com/michenriksen/hugo-theme-til"
        title="Today I Learned &#8212; A Hugo theme by Michael Henriksen"
        data-theme-version="0.4.0"
        >theme: til</a
      >
    </div>
</section>

      </footer>
    </div>

    
    <button id="back-to-top" title="Go to top">☝️</button>


    
    

    
    <script src="/js/back-to-top.js"></script>

     
    <script src="/js/cat-cursor.js" defer></script>
  </body>
</html>
