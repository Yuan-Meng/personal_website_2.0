<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Information retrieval on Yuan Meng</title>
    <link>http://localhost:50097/categories/information-retrieval/</link>
    <description>Recent content in Information retrieval on Yuan Meng</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <managingEditor>mycaptainmy@gmail.com (Yuan Meng)</managingEditor>
    <webMaster>mycaptainmy@gmail.com (Yuan Meng)</webMaster>
    <copyright>Yuan Meng</copyright>
    <lastBuildDate>Mon, 01 Jan 0001 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:50097/categories/information-retrieval/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Down the Rabbit Hole: Sequential User Modeling</title>
      <link>http://localhost:50097/posts/seq_user_modeling/</link>
      <pubDate>Sun, 17 Nov 2024 00:00:00 +0000</pubDate><author>mycaptainmy@gmail.com (Yuan Meng)</author>
      <guid>http://localhost:50097/posts/seq_user_modeling/</guid>
      <description>&lt;h2 id=&#34;catch-the-train-of-actions&#34; class=&#34;scroll-mt-8 group&#34;&gt;&#xA;  Catch the Train of Actions&#xA;  &#xA;    &lt;a href=&#34;#catch-the-train-of-actions&#34;&#xA;        class=&#34;no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block&#34;&#xA;        aria-hidden=&#34;true&#34; title=&#34;Link to this heading&#34; tabindex=&#34;-1&#34;&gt;&#xA;        &lt;svg&#xA;  xmlns=&#34;http://www.w3.org/2000/svg&#34;&#xA;  width=&#34;16&#34;&#xA;  height=&#34;16&#34;&#xA;  fill=&#34;none&#34;&#xA;  stroke=&#34;currentColor&#34;&#xA;  stroke-linecap=&#34;round&#34;&#xA;  stroke-linejoin=&#34;round&#34;&#xA;  stroke-width=&#34;2&#34;&#xA;  class=&#34;lucide lucide-link w-4 h-4 block&#34;&#xA;  viewBox=&#34;0 0 24 24&#34;&#xA;&gt;&#xA;  &lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; /&gt;&#xA;  &lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; /&gt;&#xA;&lt;/svg&gt;&#xA;&#xA;    &lt;/a&gt;&#xA;  &#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Shown below is my Amazon browsing history last week. Any recommendations on what I might buy next?&lt;/p&gt;&#xA;&lt;figure&gt;&lt;img src=&#34;https://www.dropbox.com/scl/fi/t3fs6pgs8rxlysnpoqeq9/Screenshot-2024-11-11-at-4.25.33-PM.png?rlkey=kv37yorsm6qdlro4y4ot496s8&amp;amp;st=p200ep0j&amp;amp;raw=1&#34;&#xA;    alt=&#34;Yuan&amp;rsquo;s Amazon browsing history last week; distinct sessions are color-coded.&#34; width=&#34;1800&#34;&gt;&lt;figcaption&gt;&#xA;      &lt;p&gt;Yuan&amp;rsquo;s Amazon browsing history last week; distinct sessions are color-coded.&lt;/p&gt;&#xA;    &lt;/figcaption&gt;&#xA;&lt;/figure&gt;</description>
    </item>
    <item>
      <title>The Annotated Multi-Task Ranker: An MMoE Code Example</title>
      <link>http://localhost:50097/posts/mtml/</link>
      <pubDate>Fri, 05 Jul 2024 00:00:00 +0000</pubDate><author>mycaptainmy@gmail.com (Yuan Meng)</author>
      <guid>http://localhost:50097/posts/mtml/</guid>
      <description>&lt;p&gt;Natural Language Processing (NLP) has an abundance of intuitively explained tutorials with code, such as Andrej Kaparthy&amp;rsquo;s &lt;a href=&#34;https://karpathy.ai/zero-to-hero.html&#34;&gt;Neural Networks: Zero to Hero&lt;/a&gt;, the viral &lt;a href=&#34;https://jalammar.github.io/illustrated-transformer/&#34;&gt;The Illustrated Transformer&lt;/a&gt; and its successor &lt;a href=&#34;https://nlp.seas.harvard.edu/annotated-transformer/&#34;&gt;The Annotated Transformer&lt;/a&gt;, Umar Jamil&amp;rsquo;s YouTube &lt;a href=&#34;https://www.youtube.com/@umarjamilai&#34;&gt;series&lt;/a&gt; dissecting SOTA models and the companion &lt;a href=&#34;https://github.com/hkproj&#34;&gt;repo&lt;/a&gt;, among others.&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Introduction to Embedding-Based Retrieval</title>
      <link>http://localhost:50097/posts/ebr/</link>
      <pubDate>Sat, 22 Jun 2024 00:00:00 +0000</pubDate><author>mycaptainmy@gmail.com (Yuan Meng)</author>
      <guid>http://localhost:50097/posts/ebr/</guid>
      <description>&lt;h2 id=&#34;so-what-is-an-embedding&#34; class=&#34;scroll-mt-8 group&#34;&gt;&#xA;  So, What is an Embedding?&#xA;  &#xA;    &lt;a href=&#34;#so-what-is-an-embedding&#34;&#xA;        class=&#34;no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block&#34;&#xA;        aria-hidden=&#34;true&#34; title=&#34;Link to this heading&#34; tabindex=&#34;-1&#34;&gt;&#xA;        &lt;svg&#xA;  xmlns=&#34;http://www.w3.org/2000/svg&#34;&#xA;  width=&#34;16&#34;&#xA;  height=&#34;16&#34;&#xA;  fill=&#34;none&#34;&#xA;  stroke=&#34;currentColor&#34;&#xA;  stroke-linecap=&#34;round&#34;&#xA;  stroke-linejoin=&#34;round&#34;&#xA;  stroke-width=&#34;2&#34;&#xA;  class=&#34;lucide lucide-link w-4 h-4 block&#34;&#xA;  viewBox=&#34;0 0 24 24&#34;&#xA;&gt;&#xA;  &lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; /&gt;&#xA;  &lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; /&gt;&#xA;&lt;/svg&gt;&#xA;&#xA;    &lt;/a&gt;&#xA;  &#xA;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Embedding&#34;&gt;Embedding&lt;/a&gt; is a classic idea in mathematical topology and machine learning (click â–¶ for definitions). You can think of embeddings as a special type of vectors.&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Evolution of Learning to Rank</title>
      <link>http://localhost:50097/posts/ltr/</link>
      <pubDate>Sat, 17 Feb 2024 00:00:00 +0000</pubDate><author>mycaptainmy@gmail.com (Yuan Meng)</author>
      <guid>http://localhost:50097/posts/ltr/</guid>
      <description>&lt;h2 id=&#34;first-thing-first&#34; class=&#34;scroll-mt-8 group&#34;&gt;&#xA;  First Thing First&#xA;  &#xA;    &lt;a href=&#34;#first-thing-first&#34;&#xA;        class=&#34;no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block&#34;&#xA;        aria-hidden=&#34;true&#34; title=&#34;Link to this heading&#34; tabindex=&#34;-1&#34;&gt;&#xA;        &lt;svg&#xA;  xmlns=&#34;http://www.w3.org/2000/svg&#34;&#xA;  width=&#34;16&#34;&#xA;  height=&#34;16&#34;&#xA;  fill=&#34;none&#34;&#xA;  stroke=&#34;currentColor&#34;&#xA;  stroke-linecap=&#34;round&#34;&#xA;  stroke-linejoin=&#34;round&#34;&#xA;  stroke-width=&#34;2&#34;&#xA;  class=&#34;lucide lucide-link w-4 h-4 block&#34;&#xA;  viewBox=&#34;0 0 24 24&#34;&#xA;&gt;&#xA;  &lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; /&gt;&#xA;  &lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; /&gt;&#xA;&lt;/svg&gt;&#xA;&#xA;    &lt;/a&gt;&#xA;  &#xA;&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Enigmas of the universe &lt;br/&gt; Cannot be known without a search &lt;br/&gt; &amp;mdash; Epica, &lt;a href=&#34;https://open.spotify.com/track/34Oz0bzAq7E1aUnKksPfJJ?si=9eabd1446a6a4ccc&#34;&gt;&lt;em&gt;Omega&lt;/em&gt;&lt;/a&gt; (2021)&lt;/p&gt;&#xA;&lt;/blockquote&gt;</description>
    </item>
    <item>
      <title>Autocompletion for Search Enginees</title>
      <link>http://localhost:50097/posts/autocomplete/</link>
      <pubDate>Sat, 06 Jan 2024 00:00:00 +0000</pubDate><author>mycaptainmy@gmail.com (Yuan Meng)</author>
      <guid>http://localhost:50097/posts/autocomplete/</guid>
      <description>&lt;p&gt;Autocompletion dates back half a century ago (&lt;a href=&#34;https://www.doc.ic.ac.uk/~shm/MI/mi3.html&#34;&gt;Longuet-Higgins &amp;amp; Ortony, 1968&lt;/a&gt;), initially designed to save keystrokes as people type and help those with physical disabilities type faster. The incomplete user input is the &lt;strong&gt;&amp;ldquo;query prefix&amp;rdquo;&lt;/strong&gt; and suggested ways of extending the prefix into a full query are &lt;strong&gt;&amp;ldquo;query completions&amp;rdquo;&lt;/strong&gt;. This feature is essential to modern text editors and search engines.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
