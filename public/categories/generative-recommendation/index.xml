<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Generative recommendation on Yuan Meng</title>
    <link>http://localhost:1313/categories/generative-recommendation/</link>
    <description>Recent content in Generative recommendation on Yuan Meng</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <managingEditor>mycaptainmy@gmail.com (Yuan Meng)</managingEditor>
    <webMaster>mycaptainmy@gmail.com (Yuan Meng)</webMaster>
    <copyright>Yuan Meng</copyright>
    <lastBuildDate>Mon, 01 Jan 0001 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/generative-recommendation/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Is Generative Recommendation the Future of RecSys?</title>
      <link>http://localhost:1313/posts/generative_recommendation/</link>
      <pubDate>Sun, 20 Jul 2025 00:00:00 +0000</pubDate><author>mycaptainmy@gmail.com (Yuan Meng)</author>
      <guid>http://localhost:1313/posts/generative_recommendation/</guid>
      <description>&lt;p&gt;For nearly a decade, recommender systems have remained largely the same. Most companies adopt YouTube&amp;rsquo;s cascade pipeline (&lt;a href=&#34;https://research.google.com/pubs/archive/45530.pdf&#34;&gt;Covington, 2016&lt;/a&gt;), which sifts through a massive corpus to retrieve $10^3$ to $10^4$ candidates (L0), narrows them down to $10^2$ to $10^3$ with a lightweight ranker (L1), before selecting the top few using a heavy ranker (L2) and making adjustments based on policy and business logic (L3). L2 architectures haven&amp;rsquo;t drifted far from Google&amp;rsquo;s Wide &amp;amp; Deep network (&lt;a href=&#34;https://arxiv.org/abs/1606.07792&#34;&gt;Cheng et al., 2016&lt;/a&gt;), with incremental improvements on feature interaction (e.g., &lt;a href=&#34;https://arxiv.org/abs/2008.13535&#34;&gt;DCN-v2&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/2102.07619&#34;&gt;MaskNet&lt;/a&gt;) and multi-task learning (e.g., &lt;a href=&#34;https://arxiv.org/abs/2311.09580&#34;&gt;MMoE&lt;/a&gt;, &lt;a href=&#34;https://dl.acm.org/doi/abs/10.1145/3383313.3412236&#34;&gt;PLE&lt;/a&gt;). These efforts culminated in Meta&amp;rsquo;s &lt;a href=&#34;https://arxiv.org/abs/2203.11014&#34;&gt;DHEN&lt;/a&gt; that combines multiple interaction modules and experts to push the limits of the so-called &amp;ldquo;Deep Learning Recommender System&amp;rdquo; (DLRM) paradigm.&lt;/p&gt;&#xA;&lt;figure&gt;&lt;img src=&#34;https://www.dropbox.com/scl/fi/96m8zb5yps9ffz9geheu7/Screenshot-2025-07-20-at-11.07.10-PM.png?rlkey=q4xtbxt3r50okrs2zo9vac2xq&amp;amp;st=fzobjxgt&amp;amp;raw=1&#34;&#xA;    alt=&#34;Recommender Systems.&#34; width=&#34;1800&#34;&gt;&lt;figcaption&gt;&#xA;      &lt;p&gt;Recommender Systems.&lt;/p&gt;&#xA;    &lt;/figcaption&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Interesting works came out when large language models (LLMs) first gained traction, such as using LLMs to re-rank documents (e.g., &lt;a href=&#34;https://arxiv.org/pdf/2306.17563&#34;&gt;Qin et al., 2023&lt;/a&gt;) &amp;mdash; but they felt more like toys than contenders to DLRM-based recommender systems, which serve millions of users with low latency and costs. This year, the tide seems to have finally turned. Companies with awesome recommender systems such as Meta, Google, Netflix, Kuaishou, Xiaohongshu, Alibaba, Baidu, Tencent, Meituan, etc. are embracing a new &amp;ldquo;Generative Recommendation&amp;rdquo; (GM) paradigm, reframing recommendation as a generative task, akin to token prediction in language. This shift has delivered the biggest model performance and business metric gains these companies have seen in years.&lt;/p&gt;&#xA;&lt;p&gt;So, what makes GM so magical, improving both model performance and efficiency? What serving changes are needed to productionize GM-based recommenders? In this blogpost, I review the past year&amp;rsquo;s GM work and distill key lessons for companies looking to follow.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
