<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Rag on Yuan Meng</title>
    <link>http://localhost:1313/categories/rag/</link>
    <description>Recent content in Rag on Yuan Meng</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <managingEditor>mycaptainmy@gmail.com (Yuan Meng)</managingEditor>
    <webMaster>mycaptainmy@gmail.com (Yuan Meng)</webMaster>
    <copyright>Yuan Meng</copyright>
    <lastBuildDate>Mon, 01 Jan 0001 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/rag/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Fundamentals of Retrieval Augmented Generation (RAG)</title>
      <link>http://localhost:1313/notes/rag/</link>
      <pubDate>Mon, 27 Oct 2025 00:00:00 +0000</pubDate><author>mycaptainmy@gmail.com (Yuan Meng)</author>
      <guid>http://localhost:1313/notes/rag/</guid>
      <description>&lt;p&gt;If you ask 100 ML engineers about their career goals, 90 of them will say they want to work on LLMs someday. If you ask which part of LLMs they want to work on, probably 80 out of those 90 will say pretraining, post-training, or whatever is perceived as &amp;ldquo;core modeling work.&amp;rdquo; Quite likely they never could. The remaining 10 may or may not land jobs on &lt;span style=&#34;background-color: #D9CEFF&#34;&gt;applied research engineering&lt;/span&gt; teams at &lt;code&gt;{OpenAI, Anthropic, xAI, GDM}&lt;/code&gt;, Perplexity, Glean, Anysphere, or the likes, building AI products (e.g., chatbots, web/enterprise search, etc.) that people commonly use. &lt;a href=&#34;https://python.langchain.com/docs/concepts/rag/&#34;&gt;Retrieval-Augmented Generation&lt;/a&gt; (RAG) and, later, &lt;a href=&#34;https://lilianweng.github.io/posts/2023-06-23-agent/&#34;&gt;AI agents&lt;/a&gt; are top technologies behind popular AI applications.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
