---
title: "Hardware-Aware Transformers for Long Sequence Modeling"
date: 2025-03-15
math: true
categories: ["gpu", "transformers"]
toc: true
---

Coming soon...

<!--more-->

<!-- how GPU works => why a game card is born for transformers and what kind(s) of computations it's optimized for or not

the Triton language

FlashAttention 1, 2, 3
Mamba
sparse transformers

how it informs sequence modeling for recommender systems

# References

## FlashAttention

## Mamba -->